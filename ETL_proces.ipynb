{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import userdata\n",
        "userdata.get('GOOGLE_CREDENTIALS_JSON')\n",
        "\n",
        "credentials_json_string = userdata.get('GOOGLE_CREDENTIALS_JSON')\n",
        "credentials_dict = json.loads(credentials_json_string)"
      ],
      "metadata": {
        "id": "VE74sTAMWnUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBBXNVlkNvwq",
        "outputId": "a6dd640c-4ee6-4120-dcc4-f58c185a0629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Autentikasi Google Sheets berhasil.\n",
            "‚ÑπÔ∏è Mencoba memuat sheet 'Datek Aset All' dari Spreadsheet ID: 1bbXV377Gu4MxJzbRWxFr_kbSZyzyP80kCyhR80TDWzQ\n",
            "‚úÖ Berhasil memuat 39696 baris data dari sheet 'Datek Aset All'.\n",
            "‚ÑπÔ∏è Mencoba memuat sheet 'Datek Aset All' dari Spreadsheet ID: 1bbXV377Gu4MxJzbRWxFr_kbSZyzyP80kCyhR80TDWzQ\n",
            "‚úÖ Berhasil memuat 39696 baris data dari sheet 'Datek Aset All'.\n",
            "‚ÑπÔ∏è Mencoba memuat sheet 'Data All' dari Spreadsheet ID: 1LMyZprJ_w3X6DC7Jqu0CpJaVQ3u8VUEMuSEADv1EMjc\n",
            "‚úÖ Berhasil memuat 151935 baris data dari sheet 'Data All'.\n",
            "\n",
            "üìã Info aset_data SEBELUM rename kolom:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39696 entries, 0 to 39695\n",
            "Data columns (total 51 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   PA                       39696 non-null  object\n",
            " 1   Tanggal RFS              39696 non-null  object\n",
            " 2   Mitra                    39696 non-null  object\n",
            " 3   Kategori                 39696 non-null  object\n",
            " 4   Area KP                  39696 non-null  object\n",
            " 5   Kota/Kab                 39696 non-null  object\n",
            " 6   Lokasi OLT               39696 non-null  object\n",
            " 7   Hostname OLT             39696 non-null  object\n",
            " 8   Kordinat OLT             39696 non-null  object\n",
            " 9   Brand OLT                39696 non-null  object\n",
            " 10  Type OLT                 39696 non-null  object\n",
            " 11  Kapasitas OLT            39696 non-null  object\n",
            " 12  Kapasitas \n",
            "port OLT      39696 non-null  object\n",
            " 13  OLT Port                 39696 non-null  object\n",
            " 14  Interface\n",
            "OLT            39696 non-null  object\n",
            " 15  FDT New/Existing         39696 non-null  object\n",
            " 16  FDT ID                   39696 non-null  object\n",
            " 17  Jumlah Splitter\n",
            " FDT     39696 non-null  object\n",
            " 18  Kapasitas Splitter \n",
            "FDT  39696 non-null  object\n",
            " 19  Koodinat FDT             39696 non-null  object\n",
            " 20  Port FDT                 39696 non-null  object\n",
            " 21  Status OSP AMARTA        39696 non-null  object\n",
            " 22  Cluster                  39696 non-null  object\n",
            " 23  Koordinat Cluster        39696 non-null  object\n",
            " 24  FATID                    39696 non-null  object\n",
            " 25  Jumlah Splitter FAT      39696 non-null  object\n",
            " 26  Kapasitas Splitter FAT   39696 non-null  object\n",
            " 27  Koodinat FAT             39696 non-null  object\n",
            " 28  Status OSP AMARTA        39696 non-null  object\n",
            " 29  Kecamatan                39696 non-null  object\n",
            " 30  Kelurahan                39696 non-null  object\n",
            " 31  Sumber Datek             39696 non-null  object\n",
            " 32  HC OLD                   39696 non-null  object\n",
            " 33  HC \n",
            "iCRM+                39696 non-null  object\n",
            " 34  TOTAL HC                 39696 non-null  object\n",
            " 35  CLEANSING\n",
            "HP             39696 non-null  object\n",
            " 36  OLT                      39696 non-null  object\n",
            " 37  UPDATE ASET              39696 non-null  object\n",
            " 38  FAT \n",
            "KONDISI             39696 non-null  object\n",
            " 39  FILTER FAT CAP           39696 non-null  object\n",
            " 40  FAT ID X                 39696 non-null  object\n",
            " 41  FAT FILTER PEMAKAIAN     39696 non-null  object\n",
            " 42  KETERANGAN FULL          39696 non-null  object\n",
            " 43  AMARTA UPDATE            39696 non-null  object\n",
            " 44  LINK DOKUMEN FEEDER      39696 non-null  object\n",
            " 45  KETERANGAN DOKUMEN       39696 non-null  object\n",
            " 46  LINK DATA ASET           39696 non-null  object\n",
            " 47  KETERANGAN DATA ASET     39696 non-null  object\n",
            " 48  LINK MAPS                39696 non-null  object\n",
            " 49  UP3                      39696 non-null  object\n",
            " 50  ULP                      39696 non-null  object\n",
            "dtypes: object(51)\n",
            "memory usage: 15.4+ MB\n",
            "\n",
            "Kolom asli: ['PA', 'Tanggal RFS', 'Mitra', 'Kategori', 'Area KP', 'Kota/Kab', 'Lokasi OLT', 'Hostname OLT', 'Kordinat OLT', 'Brand OLT', 'Type OLT', 'Kapasitas OLT', 'Kapasitas \\nport OLT', 'OLT Port', 'Interface\\nOLT', 'FDT New/Existing', 'FDT ID', 'Jumlah Splitter\\n FDT', 'Kapasitas Splitter \\nFDT', 'Koodinat FDT', 'Port FDT', 'Status OSP AMARTA', 'Cluster', 'Koordinat Cluster', 'FATID', 'Jumlah Splitter FAT', 'Kapasitas Splitter FAT', 'Koodinat FAT', 'Status OSP AMARTA', 'Kecamatan', 'Kelurahan', 'Sumber Datek', 'HC OLD', 'HC \\niCRM+', 'TOTAL HC', 'CLEANSING\\nHP', 'OLT ', 'UPDATE ASET', 'FAT \\nKONDISI', 'FILTER FAT CAP', 'FAT ID X', 'FAT FILTER PEMAKAIAN', 'KETERANGAN FULL', 'AMARTA UPDATE', 'LINK DOKUMEN FEEDER', 'KETERANGAN DOKUMEN', 'LINK DATA ASET', 'KETERANGAN DATA ASET', 'LINK MAPS', 'UP3', 'ULP']\n",
            "\n",
            "‚úÖ Kolom duplikat 'Status OSP AMARTA' berhasil di-rename.\n",
            "\n",
            "üìã Info aset_data SETELAH rename kolom:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39696 entries, 0 to 39695\n",
            "Data columns (total 51 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   PA                       39696 non-null  object\n",
            " 1   Tanggal RFS              39696 non-null  object\n",
            " 2   Mitra                    39696 non-null  object\n",
            " 3   Kategori                 39696 non-null  object\n",
            " 4   Area KP                  39696 non-null  object\n",
            " 5   Kota/Kab                 39696 non-null  object\n",
            " 6   Lokasi OLT               39696 non-null  object\n",
            " 7   Hostname OLT             39696 non-null  object\n",
            " 8   Kordinat OLT             39696 non-null  object\n",
            " 9   Brand OLT                39696 non-null  object\n",
            " 10  Type OLT                 39696 non-null  object\n",
            " 11  Kapasitas OLT            39696 non-null  object\n",
            " 12  Kapasitas \n",
            "port OLT      39696 non-null  object\n",
            " 13  OLT Port                 39696 non-null  object\n",
            " 14  Interface\n",
            "OLT            39696 non-null  object\n",
            " 15  FDT New/Existing         39696 non-null  object\n",
            " 16  FDT ID                   39696 non-null  object\n",
            " 17  Jumlah Splitter\n",
            " FDT     39696 non-null  object\n",
            " 18  Kapasitas Splitter \n",
            "FDT  39696 non-null  object\n",
            " 19  Koodinat FDT             39696 non-null  object\n",
            " 20  Port FDT                 39696 non-null  object\n",
            " 21  Status OSP AMARTA 1      39696 non-null  object\n",
            " 22  Cluster                  39696 non-null  object\n",
            " 23  Koordinat Cluster        39696 non-null  object\n",
            " 24  FATID                    39696 non-null  object\n",
            " 25  Jumlah Splitter FAT      39696 non-null  object\n",
            " 26  Kapasitas Splitter FAT   39696 non-null  object\n",
            " 27  Koodinat FAT             39696 non-null  object\n",
            " 28  Status OSP AMARTA 2      39696 non-null  object\n",
            " 29  Kecamatan                39696 non-null  object\n",
            " 30  Kelurahan                39696 non-null  object\n",
            " 31  Sumber Datek             39696 non-null  object\n",
            " 32  HC OLD                   39696 non-null  object\n",
            " 33  HC \n",
            "iCRM+                39696 non-null  object\n",
            " 34  TOTAL HC                 39696 non-null  object\n",
            " 35  CLEANSING\n",
            "HP             39696 non-null  object\n",
            " 36  OLT                      39696 non-null  object\n",
            " 37  UPDATE ASET              39696 non-null  object\n",
            " 38  FAT \n",
            "KONDISI             39696 non-null  object\n",
            " 39  FILTER FAT CAP           39696 non-null  object\n",
            " 40  FAT ID X                 39696 non-null  object\n",
            " 41  FAT FILTER PEMAKAIAN     39696 non-null  object\n",
            " 42  KETERANGAN FULL          39696 non-null  object\n",
            " 43  AMARTA UPDATE            39696 non-null  object\n",
            " 44  LINK DOKUMEN FEEDER      39696 non-null  object\n",
            " 45  KETERANGAN DOKUMEN       39696 non-null  object\n",
            " 46  LINK DATA ASET           39696 non-null  object\n",
            " 47  KETERANGAN DATA ASET     39696 non-null  object\n",
            " 48  LINK MAPS                39696 non-null  object\n",
            " 49  UP3                      39696 non-null  object\n",
            " 50  ULP                      39696 non-null  object\n",
            "dtypes: object(51)\n",
            "memory usage: 15.4+ MB\n",
            "\n",
            "Kolom setelah rename: ['PA', 'Tanggal RFS', 'Mitra', 'Kategori', 'Area KP', 'Kota/Kab', 'Lokasi OLT', 'Hostname OLT', 'Kordinat OLT', 'Brand OLT', 'Type OLT', 'Kapasitas OLT', 'Kapasitas \\nport OLT', 'OLT Port', 'Interface\\nOLT', 'FDT New/Existing', 'FDT ID', 'Jumlah Splitter\\n FDT', 'Kapasitas Splitter \\nFDT', 'Koodinat FDT', 'Port FDT', 'Status OSP AMARTA 1', 'Cluster', 'Koordinat Cluster', 'FATID', 'Jumlah Splitter FAT', 'Kapasitas Splitter FAT', 'Koodinat FAT', 'Status OSP AMARTA 2', 'Kecamatan', 'Kelurahan', 'Sumber Datek', 'HC OLD', 'HC \\niCRM+', 'TOTAL HC', 'CLEANSING\\nHP', 'OLT ', 'UPDATE ASET', 'FAT \\nKONDISI', 'FILTER FAT CAP', 'FAT ID X', 'FAT FILTER PEMAKAIAN', 'KETERANGAN FULL', 'AMARTA UPDATE', 'LINK DOKUMEN FEEDER', 'KETERANGAN DOKUMEN', 'LINK DATA ASET', 'KETERANGAN DATA ASET', 'LINK MAPS', 'UP3', 'ULP']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 151935 entries, 0 to 151934\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count   Dtype \n",
            "---  ------              --------------   ----- \n",
            " 0   SID                 151935 non-null  object\n",
            " 1   ID Permohonan       151935 non-null  object\n",
            " 2   Koodinat Pelanggan  151935 non-null  object\n",
            " 3   Cust Name           151935 non-null  object\n",
            " 4   Telpn               151935 non-null  object\n",
            " 5   ID FAT              151935 non-null  object\n",
            " 6   Koordinat FAT       151935 non-null  object\n",
            " 7   Hostname OLT        151935 non-null  object\n",
            " 8   FDT                 151935 non-null  object\n",
            " 9   NOTES               151935 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 11.6+ MB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "# ========== Setup ==========\n",
        "\n",
        "# Buat folder untuk data hasil pembersihan\n",
        "os.makedirs(\"data_clean\", exist_ok=True)\n",
        "\n",
        "# Scope dan kredensial\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
        "try:\n",
        "    credentials = ServiceAccountCredentials.from_json_keyfile_dict(credentials_dict, scope)\n",
        "    client = gspread.authorize(credentials)\n",
        "    print(\"‚úÖ Autentikasi Google Sheets berhasil.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Gagal melakukan autentikasi Google Sheets: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ID Google Spreadsheet\n",
        "SPREADSHEET_ID_ASET = \"1bbXV377Gu4MxJzbRWxFr_kbSZyzyP80kCyhR80TDWzQ\"\n",
        "SHEET_NAME_ASET = \"Datek Aset All\"\n",
        "SPREADSHEET_ID_USER = \"1LMyZprJ_w3X6DC7Jqu0CpJaVQ3u8VUEMuSEADv1EMjc\"\n",
        "SHEET_NAME_USER = \"Data All\"\n",
        "\n",
        "\n",
        "# ========== Extract ==========\n",
        "\n",
        "def load_sheet_as_dataframe(spreadsheet_id, sheet_name):\n",
        "    \"\"\"Memuat data dari Google Sheet ke Pandas DataFrame.\"\"\"\n",
        "    try:\n",
        "        print(f\"‚ÑπÔ∏è Mencoba memuat sheet '{sheet_name}' dari Spreadsheet ID: {spreadsheet_id}\")\n",
        "        sheet = client.open_by_key(spreadsheet_id).worksheet(sheet_name)\n",
        "        data = sheet.get_all_values()\n",
        "        if len(data) > 1:\n",
        "            df = pd.DataFrame(data[1:], columns=data[0])\n",
        "            print(f\"‚úÖ Berhasil memuat {len(df)} baris data dari sheet '{sheet_name}'.\")\n",
        "            return df\n",
        "        elif len(data) == 1:\n",
        "             print(f\"‚ö†Ô∏è Sheet '{sheet_name}' hanya berisi header.\")\n",
        "             return pd.DataFrame(columns=data[0])\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Sheet '{sheet_name}' kosong.\")\n",
        "            return pd.DataFrame()\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        print(f\"‚ùå Gagal memuat: Worksheet '{sheet_name}' tidak ditemukan di Spreadsheet ID {spreadsheet_id}.\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Gagal memuat sheet '{sheet_name}': {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "raw_aset_data = load_sheet_as_dataframe(SPREADSHEET_ID_ASET, SHEET_NAME_ASET)\n",
        "aset_data = load_sheet_as_dataframe(SPREADSHEET_ID_ASET, SHEET_NAME_ASET)\n",
        "user_data = load_sheet_as_dataframe(SPREADSHEET_ID_USER, SHEET_NAME_USER)\n",
        "\n",
        "# ========== Transform (Rename Duplicate Columns) ==========\n",
        "\n",
        "if not aset_data.empty:\n",
        "    print(\"\\nüìã Info aset_data SEBELUM rename kolom:\")\n",
        "    aset_data.info()\n",
        "    print(\"\\nKolom asli:\", list(aset_data.columns))\n",
        "\n",
        "    target_col_name = \"Status OSP AMARTA\"\n",
        "    new_cols = []\n",
        "    count = 1\n",
        "    duplicates_found = False\n",
        "\n",
        "    for col in aset_data.columns:\n",
        "        current_col_name = col\n",
        "        if col == target_col_name:\n",
        "            new_name = f\"{target_col_name} {count}\"\n",
        "            new_cols.append(new_name)\n",
        "            if count > 1:\n",
        "                 duplicates_found = True\n",
        "            count += 1\n",
        "        else:\n",
        "            new_cols.append(col)\n",
        "\n",
        "    # Hanya ganti nama kolom jika memang ditemukan duplikat (count > 2 berarti ada minimal 2 kolom target)\n",
        "    if duplicates_found:\n",
        "        aset_data.columns = new_cols\n",
        "        print(f\"\\n‚úÖ Kolom duplikat '{target_col_name}' berhasil di-rename.\")\n",
        "    elif count == 2:\n",
        "         print(f\"\\n‚ÑπÔ∏è Hanya ditemukan satu kolom '{target_col_name}'. Tidak ada rename duplikat yang dilakukan.\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è Kolom '{target_col_name}' tidak ditemukan dalam data aset.\")\n",
        "\n",
        "\n",
        "    # Menampilkan info setelah potensi perubahan kolom\n",
        "    print(\"\\nüìã Info aset_data SETELAH rename kolom:\")\n",
        "    aset_data.info()\n",
        "    print(\"\\nKolom setelah rename:\", list(aset_data.columns))\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è DataFrame aset_data kosong, proses rename dilewati.\")\n",
        "user_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_column_names(df):\n",
        "    df.columns = [re.sub(r\"\\s+\", \" \", col).strip() for col in df.columns]\n",
        "    return df\n",
        "\n",
        "aset_data = clean_column_names(aset_data)\n",
        "user_data = clean_column_names(user_data)\n",
        "\n",
        "\n",
        "# # ========== Transform ==========\n",
        "\n",
        "def capitalize_columns_except(df, exclude_columns):\n",
        "    \"\"\"\n",
        "    Capitalize each word in string columns, except for the columns specified in exclude_columns.\n",
        "    Cleans column names to remove excessive whitespace as well.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Bersihkan nama kolom (strip dan ubah spasi ganda jadi 1 spasi)\n",
        "    df.columns = [re.sub(r\"\\s+\", \" \", col).strip() for col in df.columns]\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_columns:\n",
        "            try:\n",
        "                df[col] = df[col].apply(lambda x: x.title() if isinstance(x, str) else x)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Gagal memproses kolom '{col}': {e}\")\n",
        "    return df\n",
        "\n",
        "# Kolom yang tidak ingin diubah\n",
        "exclude_columns = [\"Hostname OLT\", \"FDT ID\", \"FATID\", \"Type OLT\", \"OLT\", \"ID FAT\", \"CLEANSING HP\", \"FAT ID X\", \"LINK DOKUMEN FEEDER\", \"LINK DATA ASET\", \"LINK MAPS\"]\n",
        "\n",
        "# # Bersihkan aset_data\n",
        "if not aset_data.empty:\n",
        "    aset_data.drop_duplicates(subset=[\"FATID\"], keep=\"first\", inplace=True)\n",
        "    aset_data = capitalize_columns_except(aset_data, exclude_columns)\n",
        "aset_data.head()\n",
        "aset_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRv_7BacpL9n",
        "outputId": "f195c507-3ebb-4c26-dfc9-dddc76066865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 51 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   PA                      38968 non-null  object\n",
            " 1   Tanggal RFS             38968 non-null  object\n",
            " 2   Mitra                   38968 non-null  object\n",
            " 3   Kategori                38968 non-null  object\n",
            " 4   Area KP                 38968 non-null  object\n",
            " 5   Kota/Kab                38968 non-null  object\n",
            " 6   Lokasi OLT              38968 non-null  object\n",
            " 7   Hostname OLT            38968 non-null  object\n",
            " 8   Kordinat OLT            38968 non-null  object\n",
            " 9   Brand OLT               38968 non-null  object\n",
            " 10  Type OLT                38968 non-null  object\n",
            " 11  Kapasitas OLT           38968 non-null  object\n",
            " 12  Kapasitas port OLT      38968 non-null  object\n",
            " 13  OLT Port                38968 non-null  object\n",
            " 14  Interface OLT           38968 non-null  object\n",
            " 15  FDT New/Existing        38968 non-null  object\n",
            " 16  FDT ID                  38968 non-null  object\n",
            " 17  Jumlah Splitter FDT     38968 non-null  object\n",
            " 18  Kapasitas Splitter FDT  38968 non-null  object\n",
            " 19  Koodinat FDT            38968 non-null  object\n",
            " 20  Port FDT                38968 non-null  object\n",
            " 21  Status OSP AMARTA 1     38968 non-null  object\n",
            " 22  Cluster                 38968 non-null  object\n",
            " 23  Koordinat Cluster       38968 non-null  object\n",
            " 24  FATID                   38968 non-null  object\n",
            " 25  Jumlah Splitter FAT     38968 non-null  object\n",
            " 26  Kapasitas Splitter FAT  38968 non-null  object\n",
            " 27  Koodinat FAT            38968 non-null  object\n",
            " 28  Status OSP AMARTA 2     38968 non-null  object\n",
            " 29  Kecamatan               38968 non-null  object\n",
            " 30  Kelurahan               38968 non-null  object\n",
            " 31  Sumber Datek            38968 non-null  object\n",
            " 32  HC OLD                  38968 non-null  object\n",
            " 33  HC iCRM+                38968 non-null  object\n",
            " 34  TOTAL HC                38968 non-null  object\n",
            " 35  CLEANSING HP            38968 non-null  object\n",
            " 36  OLT                     38968 non-null  object\n",
            " 37  UPDATE ASET             38968 non-null  object\n",
            " 38  FAT KONDISI             38968 non-null  object\n",
            " 39  FILTER FAT CAP          38968 non-null  object\n",
            " 40  FAT ID X                38968 non-null  object\n",
            " 41  FAT FILTER PEMAKAIAN    38968 non-null  object\n",
            " 42  KETERANGAN FULL         38968 non-null  object\n",
            " 43  AMARTA UPDATE           38968 non-null  object\n",
            " 44  LINK DOKUMEN FEEDER     38968 non-null  object\n",
            " 45  KETERANGAN DOKUMEN      38968 non-null  object\n",
            " 46  LINK DATA ASET          38968 non-null  object\n",
            " 47  KETERANGAN DATA ASET    38968 non-null  object\n",
            " 48  LINK MAPS               38968 non-null  object\n",
            " 49  UP3                     38968 non-null  object\n",
            " 50  ULP                     38968 non-null  object\n",
            "dtypes: object(51)\n",
            "memory usage: 15.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataframe(df, exclude_columns):\n",
        "    \"\"\"\n",
        "    Bersihkan header kolom dan kapitalisasi isi string, kecuali kolom di exclude_columns.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Bersihkan nama kolom: hilangkan spasi ekstra dan strip\n",
        "    df.columns = [re.sub(r\"\\s+\", \" \", col).strip() for col in df.columns]\n",
        "\n",
        "    # Bersihkan isi string di setiap kolom, lalu kapitalisasi jika bukan di exclude_columns\n",
        "    for col in df.columns:\n",
        "        if col not in exclude_columns:\n",
        "            try:\n",
        "                df[col] = df[col].apply(lambda x: re.sub(r\"\\s+\", \" \", x.strip()).title() if isinstance(x, str) else x)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Gagal memproses kolom '{col}': {e}\")\n",
        "    return df\n",
        "\n",
        "# # Bersihkan user_data\n",
        "if not user_data.empty:\n",
        "    user_data = (\n",
        "        user_data.sort_values(\n",
        "            by=[\"SID\", \"Cust Name\", \"Koodinat Pelanggan\"],\n",
        "            ascending=False,\n",
        "            na_position=\"last\"\n",
        "        )\n",
        "        .drop_duplicates(subset=[\"ID Permohonan\"], keep=\"first\")\n",
        "    )\n",
        "    user_data = clean_dataframe(user_data, exclude_columns)\n",
        "    kolom_yang_dihapus = [\n",
        "    'Koordinat FAT', 'Hostname OLT', 'FDT'\n",
        "]\n",
        "    user_data.drop(columns=kolom_yang_dihapus, inplace=True, errors='ignore')\n",
        "\n",
        "# ========== Load (Opsional Simpan ke File) ==========\n",
        "\n",
        "# aset_data.to_csv(\"data_clean/aset_data_clean.csv\", index=False)\n",
        "# user_data.to_csv(\"data_clean/user_data_clean.csv\", index=False)\n",
        "\n",
        "# ========== Log ==========\n",
        "\n",
        "print(\"üìã Info aset_data setelah transformasi:\")\n",
        "print(aset_data.info())\n",
        "print(\"\\nüìã Info user_data setelah transformasi:\")\n",
        "print(user_data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJIEHL8rp9Wk",
        "outputId": "535e3adc-cc80-4f3e-fa93-5ee52e471027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Info aset_data setelah transformasi:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 51 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   PA                      38968 non-null  object\n",
            " 1   Tanggal RFS             38968 non-null  object\n",
            " 2   Mitra                   38968 non-null  object\n",
            " 3   Kategori                38968 non-null  object\n",
            " 4   Area KP                 38968 non-null  object\n",
            " 5   Kota/Kab                38968 non-null  object\n",
            " 6   Lokasi OLT              38968 non-null  object\n",
            " 7   Hostname OLT            38968 non-null  object\n",
            " 8   Kordinat OLT            38968 non-null  object\n",
            " 9   Brand OLT               38968 non-null  object\n",
            " 10  Type OLT                38968 non-null  object\n",
            " 11  Kapasitas OLT           38968 non-null  object\n",
            " 12  Kapasitas port OLT      38968 non-null  object\n",
            " 13  OLT Port                38968 non-null  object\n",
            " 14  Interface OLT           38968 non-null  object\n",
            " 15  FDT New/Existing        38968 non-null  object\n",
            " 16  FDT ID                  38968 non-null  object\n",
            " 17  Jumlah Splitter FDT     38968 non-null  object\n",
            " 18  Kapasitas Splitter FDT  38968 non-null  object\n",
            " 19  Koodinat FDT            38968 non-null  object\n",
            " 20  Port FDT                38968 non-null  object\n",
            " 21  Status OSP AMARTA 1     38968 non-null  object\n",
            " 22  Cluster                 38968 non-null  object\n",
            " 23  Koordinat Cluster       38968 non-null  object\n",
            " 24  FATID                   38968 non-null  object\n",
            " 25  Jumlah Splitter FAT     38968 non-null  object\n",
            " 26  Kapasitas Splitter FAT  38968 non-null  object\n",
            " 27  Koodinat FAT            38968 non-null  object\n",
            " 28  Status OSP AMARTA 2     38968 non-null  object\n",
            " 29  Kecamatan               38968 non-null  object\n",
            " 30  Kelurahan               38968 non-null  object\n",
            " 31  Sumber Datek            38968 non-null  object\n",
            " 32  HC OLD                  38968 non-null  object\n",
            " 33  HC iCRM+                38968 non-null  object\n",
            " 34  TOTAL HC                38968 non-null  object\n",
            " 35  CLEANSING HP            38968 non-null  object\n",
            " 36  OLT                     38968 non-null  object\n",
            " 37  UPDATE ASET             38968 non-null  object\n",
            " 38  FAT KONDISI             38968 non-null  object\n",
            " 39  FILTER FAT CAP          38968 non-null  object\n",
            " 40  FAT ID X                38968 non-null  object\n",
            " 41  FAT FILTER PEMAKAIAN    38968 non-null  object\n",
            " 42  KETERANGAN FULL         38968 non-null  object\n",
            " 43  AMARTA UPDATE           38968 non-null  object\n",
            " 44  LINK DOKUMEN FEEDER     38968 non-null  object\n",
            " 45  KETERANGAN DOKUMEN      38968 non-null  object\n",
            " 46  LINK DATA ASET          38968 non-null  object\n",
            " 47  KETERANGAN DATA ASET    38968 non-null  object\n",
            " 48  LINK MAPS               38968 non-null  object\n",
            " 49  UP3                     38968 non-null  object\n",
            " 50  ULP                     38968 non-null  object\n",
            "dtypes: object(51)\n",
            "memory usage: 15.5+ MB\n",
            "None\n",
            "\n",
            "üìã Info user_data setelah transformasi:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 139016 entries, 5167 to 148442\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count   Dtype \n",
            "---  ------              --------------   ----- \n",
            " 0   SID                 139016 non-null  object\n",
            " 1   ID Permohonan       139016 non-null  object\n",
            " 2   Koodinat Pelanggan  139016 non-null  object\n",
            " 3   Cust Name           139016 non-null  object\n",
            " 4   Telpn               139016 non-null  object\n",
            " 5   ID FAT              139016 non-null  object\n",
            " 6   NOTES               139016 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 8.5+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aset_data.rename(columns={\n",
        "    # Kolom dari Tabel OLT\n",
        "    \"Hostname OLT\": \"hostname_olt\",\n",
        "    \"Kordinat OLT\": \"koordinat_olt\",\n",
        "    \"Brand OLT\": \"brand_olt\",\n",
        "    \"Type OLT\": \"type_olt\",\n",
        "    \"Kapasitas OLT\": \"kapasitas_olt\",\n",
        "    \"Kapasitas port OLT\": \"kapasitas_port_olt\",\n",
        "    \"OLT Port\": \"olt_port\",\n",
        "    \"OLT\": \"olt\",\n",
        "    \"Interface OLT\": \"interface_olt\",\n",
        "    \"Lokasi OLT\": \"lokasi_olt\",\n",
        "\n",
        "    # Kolom dari Tabel FDT\n",
        "    \"FDT ID\": \"fdt_id\",\n",
        "    \"Status OSP AMARTA 1\": \"status_osp_amarta_fdt\",\n",
        "    \"Jumlah Splitter FDT\": \"jumlah_splitter_fdt\",\n",
        "    \"Kapasitas Splitter FDT\": \"kapasitas_splitter_fdt\",\n",
        "    \"FDT New/Existing\": \"fdt_new_existing\",\n",
        "    \"Port FDT\": \"port_fdt\",\n",
        "    \"Koodinat FDT\": \"koordinat_fdt\",\n",
        "\n",
        "    # Kolom dari Tabel FAT\n",
        "    \"FATID\": \"fat_id\",\n",
        "    \"Jumlah Splitter FAT\": \"jumlah_splitter_fat\",\n",
        "    \"Kapasitas Splitter FAT\": \"kapasitas_splitter_fat\",\n",
        "    \"Koodinat FAT\": \"koordinat_fat\",\n",
        "    \"Status OSP AMARTA FAT\": \"status_osp_amarta_fat\",\n",
        "    \"FAT KONDISI\": \"fat_kondisi\",\n",
        "    \"FAT FILTER PEMAKAIAN\": \"fat_filter_pemakaian\",\n",
        "    \"KETERANGAN FULL\": \"keterangan_full\",\n",
        "    \"FAT ID X\": \"fat_id_x\",\n",
        "    \"FILTER FAT CAP\": \"filter_fat_cap\",\n",
        "    \"Status OSP AMARTA 2\": \"status_osp_amarta_fat\",\n",
        "\n",
        "    # Kolom dari Tabel Cluster\n",
        "    \"Cluster\": \"cluster\",\n",
        "    \"Koordinat Cluster\": \"koordinat_cluster\",\n",
        "    \"Area KP\": \"area_kp\",\n",
        "    \"Kota/Kab\": \"kota_kab\",\n",
        "    \"Kecamatan\": \"kecamatan\",\n",
        "    \"Kelurahan\": \"kelurahan\",\n",
        "    \"UP3\": \"up3\",\n",
        "    \"ULP\": \"ulp\",\n",
        "\n",
        "    # Kolom dari Tabel Dokumentasi\n",
        "    \"LINK DOKUMEN FEEDER\": \"link_dokumen_feeder\",\n",
        "    \"KETERANGAN DOKUMEN\": \"keterangan_dokumen\",\n",
        "    \"LINK DATA ASET\": \"link_data_aset\",\n",
        "    \"KETERANGAN DATA ASET\": \"keterangan_data_aset\",\n",
        "    \"LINK MAPS\": \"link_maps\",\n",
        "    \"UPDATE ASET\": \"update_aset\",\n",
        "    \"AMARTA UPDATE\": \"amarta_update\",\n",
        "\n",
        "    # Kolom dari Tabel HomeConnected\n",
        "    \"HC OLD\": \"hc_old\",\n",
        "    \"HC iCRM+\": \"hc_icrm\",\n",
        "    \"TOTAL HC\": \"total_hc\",\n",
        "    \"CLEANSING HP\": \"cleansing_hp\",\n",
        "\n",
        "    # Kolom dari Tabel AdditionalInformation\n",
        "    \"PA\": \"pa\",\n",
        "    \"Tanggal RFS\": \"tanggal_rfs\",\n",
        "    \"Mitra\": \"mitra\",\n",
        "    \"Kategori\": \"kategori\",\n",
        "    \"Sumber Datek\": \"sumber_datek\"\n",
        "}, inplace=True)\n",
        "\n",
        "user_data.rename(columns={\n",
        "    \"SID\": \"sid\",\n",
        "    \"ID Permohonan\": \"id_permohonan\",\n",
        "    \"Koodinat Pelanggan\": \"koordinat_pelanggan\",\n",
        "    \"Cust Name\": \"cust_name\",\n",
        "    \"Telpn\": \"telpn\",\n",
        "    \"ID FAT\": \"fat_id\",\n",
        "    \"NOTES\": \"notes\"\n",
        "}, inplace=True)\n",
        "aset_data.info()\n",
        "user_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJUEIuVvu4YI",
        "outputId": "b8d1385b-6631-4a61-a81d-795d6a73f163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 51 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   pa                      38968 non-null  object\n",
            " 1   tanggal_rfs             38968 non-null  object\n",
            " 2   mitra                   38968 non-null  object\n",
            " 3   kategori                38968 non-null  object\n",
            " 4   area_kp                 38968 non-null  object\n",
            " 5   kota_kab                38968 non-null  object\n",
            " 6   lokasi_olt              38968 non-null  object\n",
            " 7   hostname_olt            38968 non-null  object\n",
            " 8   koordinat_olt           38968 non-null  object\n",
            " 9   brand_olt               38968 non-null  object\n",
            " 10  type_olt                38968 non-null  object\n",
            " 11  kapasitas_olt           38968 non-null  object\n",
            " 12  kapasitas_port_olt      38968 non-null  object\n",
            " 13  olt_port                38968 non-null  object\n",
            " 14  interface_olt           38968 non-null  object\n",
            " 15  fdt_new_existing        38968 non-null  object\n",
            " 16  fdt_id                  38968 non-null  object\n",
            " 17  jumlah_splitter_fdt     38968 non-null  object\n",
            " 18  kapasitas_splitter_fdt  38968 non-null  object\n",
            " 19  koordinat_fdt           38968 non-null  object\n",
            " 20  port_fdt                38968 non-null  object\n",
            " 21  status_osp_amarta_fdt   38968 non-null  object\n",
            " 22  cluster                 38968 non-null  object\n",
            " 23  koordinat_cluster       38968 non-null  object\n",
            " 24  fat_id                  38968 non-null  object\n",
            " 25  jumlah_splitter_fat     38968 non-null  object\n",
            " 26  kapasitas_splitter_fat  38968 non-null  object\n",
            " 27  koordinat_fat           38968 non-null  object\n",
            " 28  status_osp_amarta_fat   38968 non-null  object\n",
            " 29  kecamatan               38968 non-null  object\n",
            " 30  kelurahan               38968 non-null  object\n",
            " 31  sumber_datek            38968 non-null  object\n",
            " 32  hc_old                  38968 non-null  object\n",
            " 33  hc_icrm                 38968 non-null  object\n",
            " 34  total_hc                38968 non-null  object\n",
            " 35  cleansing_hp            38968 non-null  object\n",
            " 36  olt                     38968 non-null  object\n",
            " 37  update_aset             38968 non-null  object\n",
            " 38  fat_kondisi             38968 non-null  object\n",
            " 39  filter_fat_cap          38968 non-null  object\n",
            " 40  fat_id_x                38968 non-null  object\n",
            " 41  fat_filter_pemakaian    38968 non-null  object\n",
            " 42  keterangan_full         38968 non-null  object\n",
            " 43  amarta_update           38968 non-null  object\n",
            " 44  link_dokumen_feeder     38968 non-null  object\n",
            " 45  keterangan_dokumen      38968 non-null  object\n",
            " 46  link_data_aset          38968 non-null  object\n",
            " 47  keterangan_data_aset    38968 non-null  object\n",
            " 48  link_maps               38968 non-null  object\n",
            " 49  up3                     38968 non-null  object\n",
            " 50  ulp                     38968 non-null  object\n",
            "dtypes: object(51)\n",
            "memory usage: 15.5+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 139016 entries, 5167 to 148442\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   sid                  139016 non-null  object\n",
            " 1   id_permohonan        139016 non-null  object\n",
            " 2   koordinat_pelanggan  139016 non-null  object\n",
            " 3   cust_name            139016 non-null  object\n",
            " 4   telpn                139016 non-null  object\n",
            " 5   fat_id               139016 non-null  object\n",
            " 6   notes                139016 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 8.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîÑ Memulai konversi tipe data...\")\n",
        "\n",
        "# --- Handle aset_data ---\n",
        "if 'aset_data' in locals() and isinstance(aset_data, pd.DataFrame) and not aset_data.empty:\n",
        "    try:\n",
        "        print(\"\\n--- Memproses aset_data ---\")\n",
        "\n",
        "        # 1. Handle 'tanggal_rfs': Koreksi Spesifik '0203'\n",
        "        if 'tanggal_rfs' in aset_data.columns:\n",
        "            print(\" ¬†-> Memproses kolom 'tanggal_rfs': Mengganti '0203' dengan '2023'.\")\n",
        "            # Pastikan kolom diperlakukan sebagai string untuk operasi replace\n",
        "            aset_data['tanggal_rfs'] = aset_data['tanggal_rfs'].astype(str)\n",
        "            # Lakukan penggantian spesifik\n",
        "            aset_data['tanggal_rfs'] = aset_data['tanggal_rfs'].str.replace('0203', '2023', regex=False)\n",
        "            # Konversi ke datetime akan dilakukan di astype() di bagian bawah jika dimasukkan di dict\n",
        "            print(\" ¬† ¬†‚úÖ Pembersihan string '0203' di 'tanggal_rfs' selesai.\")\n",
        "\n",
        "\n",
        "        # 2. Define the original dictionary with all intended types\n",
        "        # Kolom-kolom Int64 di sini akan diproses secara terpisah terlebih dahulu\n",
        "        original_astype_dict_aset = {\n",
        "             # Tabel OLT\n",
        "            \"hostname_olt\": \"string\", \"Koordinat_olt\": \"string\", \"brand_olt\": \"string\", \"type_olt\": \"string\",\n",
        "            \"kapasitas_olt\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"kapasitas_port_olt\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"olt_port\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"olt\": \"string\", \"interface_olt\": \"string\",\n",
        "            # Tabel FDT\n",
        "            \"fdt_id\": \"string\", \"status_osp_amarta_fdt\": \"string\", \"jumlah_splitter_fdt\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"kapasitas_splitter_fdt\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"fdt_new_existing\": \"string\", \"port_fdt\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"koordinat_fdt\": \"string\",\n",
        "            # Tabel FAT\n",
        "            \"fat_id\": \"string\", \"jumlah_splitter_fat\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"kapasitas_splitter_fat\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"koordinat_fat\": \"string\",\n",
        "            \"status_osp_amarta_fat\": \"string\", \"fat_kondisi\": \"string\", \"fat_filter_pemakaian\": \"string\", \"keterangan_full\": \"string\",\n",
        "            \"fat_id_x\": \"string\", \"filter_fat_cap\": \"string\",\n",
        "            # Tabel Cluster\n",
        "            \"cluster\":\"string\",\"koordinat_cluster\": \"string\", \"area_kp\": \"string\", \"kota_kab\": \"string\", \"kecamatan\": \"string\", \"kelurahan\": \"string\",\n",
        "            \"up3\": \"string\", \"ulp\": \"string\",\n",
        "            # Dokumentasi\n",
        "            \"link_dokumen_feeder\": \"string\", \"keterangan_dokumen\": \"string\", \"link_data_aset\": \"string\", \"keterangan_data_aset\": \"string\",\n",
        "            \"link_maps\": \"string\", \"update_aset\": \"string\", \"amarta_update\": \"string\",\n",
        "            # HomeConnected\n",
        "            \"hc_old\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"hc_icrm\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"total_hc\": \"Int64\", # Target Int64 - akan diproses khusus\n",
        "            \"cleansing_hp\": \"string\",\n",
        "            # Additional Info\n",
        "            \"pa\": \"string\",\n",
        "            \"tanggal_rfs\":\"datetime64[ns]\", # Target datetime - akan diproses di astype umum\n",
        "            \"mitra\": \"string\", \"kategori\": \"string\", \"sumber_datek\": \"string\"\n",
        "        }\n",
        "\n",
        "        # Identifikasi kolom-kolom yang ditargetkan untuk Int64\n",
        "        int64_cols_to_process = [col for col, dtype in original_astype_dict_aset.items() if dtype == 'Int64']\n",
        "        other_cols_to_astype = {col: dtype for col, dtype in original_astype_dict_aset.items() if dtype != 'Int64'}\n",
        "\n",
        "        print(\"\\n ¬†--- Memproses Kolom Target Int64 ---\")\n",
        "        processed_int64_cols = [] # Untuk melacak kolom yang berhasil diproses\n",
        "        for col in int64_cols_to_process:\n",
        "            if col in aset_data.columns:\n",
        "                print(f\" ¬†-> Memproses kolom '{col}': Membersihkan dan konversi ke Int64.\")\n",
        "                try:\n",
        "                    # Hitung jumlah nilai yang tidak kosong sebelum diproses\n",
        "                    initial_non_null_count = aset_data[col].notnull().sum()\n",
        "                    # print(f\" ¬† ¬†-> Awalnya terdapat {initial_non_null_count} nilai non-kosong.\") # Opsional detail\n",
        "\n",
        "                    # Pastikan kolom string untuk operasi string\n",
        "                    cleaned_series = aset_data[col].astype(str).copy()\n",
        "\n",
        "                    # Hapus karakter titik, koma, atau spasi yang mungkin ada\n",
        "                    # Regex [., ] akan menghapus titik, koma, atau spasi\n",
        "                    # Tambahkan strip() untuk menghapus spasi di awal/akhir string\n",
        "                    cleaned_series = cleaned_series.str.replace('[., ]', '', regex=True).str.strip()\n",
        "\n",
        "                    # Konversi ke Int64 (ini juga menangani NaNs dari coerce)\n",
        "                    numeric_series = pd.to_numeric(cleaned_series, errors='coerce')\n",
        "                    aset_data[col] = numeric_series.astype('Int64')\n",
        "\n",
        "                    # Hitung jumlah nilai yang tidak kosong setelah diproses\n",
        "                    final_non_null_count = aset_data[col].notnull().sum()\n",
        "                    # print(f\" ¬† ¬†-> Setelah pembersihan dan konversi, terdapat {final_non_null_count} nilai non-kosong.\") # Opsional detail\n",
        "\n",
        "                    # Hitung berapa banyak nilai yang awalnya tidak kosong menjadi kosong (NaN)\n",
        "                    num_converted_to_nan = initial_non_null_count - final_non_null_count\n",
        "\n",
        "                    if num_converted_to_nan > 0:\n",
        "                        print(f\" ¬† ¬†‚ö†Ô∏è Terdapat {num_converted_to_nan} nilai di '{col}' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\")\n",
        "                    else:\n",
        "                         print(f\" ¬† ¬†‚úÖ Tidak ada nilai di '{col}' yang awalnya tidak kosong diubah menjadi kosong (NaN).\")\n",
        "\n",
        "                    print(f\" ¬† ¬†‚úÖ Pembersihan dan konversi '{col}' ke Int64 selesai.\")\n",
        "                    processed_int64_cols.append(col) # Tandai kolom ini berhasil diproses\n",
        "\n",
        "                except Exception as col_e:\n",
        "                     print(f\" ¬† ¬†‚ùå Gagal memproses kolom '{col}' secara spesifik: {col_e}\")\n",
        "                     print(f\" ¬† ¬†‚ÑπÔ∏è Kolom '{col}' mungkin tidak dikonversi ke Int64 karena error.\")\n",
        "            else:\n",
        "                 print(f\" ¬†-> Kolom '{col}' tidak ditemukan di aset_data. Dilewati.\")\n",
        "\n",
        "\n",
        "        print(\"\\n ¬†--- Mengonversi Kolom Lainnya ---\")\n",
        "        # Filter dictionary untuk hanya menyertakan kolom yang masih perlu di-astype\n",
        "        # Yaitu kolom yang bukan Int64 target awalnya ATAU kolom Int64 target yang gagal diproses di atas\n",
        "        valid_astype_dict_aset = {}\n",
        "        missing_cols_aset = []\n",
        "        for col, dtype in other_cols_to_astype.items():\n",
        "             if col in aset_data.columns:\n",
        "                 valid_astype_dict_aset[col] = dtype\n",
        "             else:\n",
        "                 missing_cols_aset.append(col)\n",
        "\n",
        "        # Cek kembali kolom Int64 yang GAGAL diproses.\n",
        "        # Secara default, jika gagal, tipenya tidak akan berubah dari object/string.\n",
        "        # Kita bisa biarkan saja di sini atau tambahkan penanganan khusus jika perlu.\n",
        "        # Untuk saat ini, biarkan saja, dan info() di akhir akan menunjukkan tipenya.\n",
        "\n",
        "        if missing_cols_aset:\n",
        "            print(f\" ¬† ¬†‚ö†Ô∏è Kolom berikut tidak ditemukan di aset_data dan dilewati dalam konversi tipe data umum: {missing_cols_aset}\")\n",
        "\n",
        "        if valid_astype_dict_aset:\n",
        "            print(\" ¬†-> Mengonversi tipe data kolom aset_data lainnya menggunakan astype...\")\n",
        "            # Lakukan astype untuk kolom yang tersisa di dictionary (termasuk tanggal_rfs ke datetime)\n",
        "            try:\n",
        "                aset_data = aset_data.astype(valid_astype_dict_aset)\n",
        "                print(\" ¬†‚úÖ Konversi tipe data aset_data (selain Int64 yang sudah ditangani) selesai.\")\n",
        "            except Exception as astype_e:\n",
        "                 # Menangkap error spesifik yang mungkin terjadi di langkah astype()\n",
        "                 print(f\"‚ùå Error saat konversi tipe data aset_data pada langkah astype() untuk kolom-kolom tersisa: {astype_e}\")\n",
        "                 print(\" ¬† ¬†‚ÑπÔ∏è Pastikan format data di kolom yang tersisa sesuai dengan tipe data target di dictionary.\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\" ¬†‚ÑπÔ∏è Tidak ada kolom lain di aset_data yang perlu dikonversi via astype.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Menangkap error tak terduga di luar blok try/except kolom spesifik atau astype umum\n",
        "        print(f\"‚ùå Error tak terduga saat konversi tipe data aset_data secara keseluruhan: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è DataFrame aset_data kosong atau tidak terdefinisi, konversi tipe data dilewati.\")\n",
        "\n",
        "\n",
        "# --- Handle user_data --- (Kode konversi user_data tetap sama)\n",
        "# ... (bagian kode user_data dari jawaban sebelumnya) ...\n",
        "try:\n",
        "    if 'user_data' in locals() and isinstance(user_data, pd.DataFrame) and not user_data.empty:\n",
        "        print(\"\\n--- Memproses user_data ---\")\n",
        "        print(\" ¬†-> Mengonversi kolom user_data...\")\n",
        "        try:\n",
        "            astype_dict_user = {\n",
        "                \"sid\": \"string\", \"id_permohonan\": \"string\", \"koordinat_pelanggan\": \"string\",\n",
        "                \"cust_name\": \"string\", \"telpn\": \"string\", \"fat_id\": \"string\",\n",
        "                \"fdt\": \"string\", \"notes\": \"string\"\n",
        "            }\n",
        "            valid_astype_dict_user = {}\n",
        "            missing_cols_user = []\n",
        "            for col, dtype in astype_dict_user.items():\n",
        "                 if col in user_data.columns:\n",
        "                     valid_astype_dict_user[col] = dtype\n",
        "                 else:\n",
        "                     missing_cols_user.append(col)\n",
        "\n",
        "            if missing_cols_user:\n",
        "                 print(f\" ¬† ¬†‚ö†Ô∏è Kolom berikut tidak ditemukan di user_data dan dilewati dalam konversi tipe data: {missing_cols_user}\")\n",
        "\n",
        "            if valid_astype_dict_user:\n",
        "                 user_data = user_data.astype(valid_astype_dict_user)\n",
        "                 print(\" ¬†‚úÖ Konversi tipe data user_data selesai.\")\n",
        "            else:\n",
        "                 print(\" ¬†‚ÑπÔ∏è Tidak ada kolom di user_data yang perlu dikonversi via astype.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saat konversi tipe data user_data: {e}\")\n",
        "\n",
        "    elif 'user_data' in locals() and isinstance(user_data, pd.DataFrame) and user_data.empty:\n",
        "          print(\"\\n‚ö†Ô∏è DataFrame user_data kosong, konversi tipe data dilewati.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"\\n‚ÑπÔ∏è Variabel user_data tidak terdefinisi. Konversi tipe data untuk user_data dilewati.\")\n",
        "\n",
        "\n",
        "# ========================= Cek hasil =========================\n",
        "# ... (bagian kode print info dari jawaban sebelumnya) ...\n",
        "print(\"\\nüìã Info aset_data setelah konversi:\")\n",
        "if 'aset_data' in locals() and isinstance(aset_data, pd.DataFrame):\n",
        "    if not aset_data.empty:\n",
        "        aset_data.info()\n",
        "        # Opsional: Print tipe data spesifik untuk kolom-kolom kunci yang diproses\n",
        "        key_cols_to_check = ['tanggal_rfs', 'kapasitas_olt', 'kapasitas_port_olt', 'olt_port', 'jumlah_splitter_fdt', 'hc_old']\n",
        "        for col in key_cols_to_check:\n",
        "            if col in aset_data.columns:\n",
        "                 print(f\" ¬† -> Tipe data kolom '{col}': {aset_data[col].dtype}\")\n",
        "    else:\n",
        "        print(\" ¬† (DataFrame kosong)\")\n",
        "else:\n",
        "    print(\" ¬† (DataFrame aset_data tidak terdefinisi)\")\n",
        "\n",
        "\n",
        "print(\"\\nüìã Info user_data setelah konversi:\")\n",
        "try:\n",
        "    if 'user_data' in locals() and isinstance(user_data, pd.DataFrame):\n",
        "        if not user_data.empty:\n",
        "            user_data.info()\n",
        "        else:\n",
        "            print(\" ¬† (DataFrame kosong)\")\n",
        "except NameError:\n",
        "    print(\" ¬† (DataFrame user_data tidak terdefinisi)\")\n",
        "\n",
        "\n",
        "print(\"\\n‚úÖ Proses konversi tipe data selesai.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBwrIx5QEFuK",
        "outputId": "ea495bac-2478-437b-b1c6-fe2cda34b599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Memulai konversi tipe data...\n",
            "\n",
            "--- Memproses aset_data ---\n",
            " ¬†-> Memproses kolom 'tanggal_rfs': Mengganti '0203' dengan '2023'.\n",
            " ¬† ¬†‚úÖ Pembersihan string '0203' di 'tanggal_rfs' selesai.\n",
            "\n",
            " ¬†--- Memproses Kolom Target Int64 ---\n",
            " ¬†-> Memproses kolom 'kapasitas_olt': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 4547 nilai di 'kapasitas_olt' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'kapasitas_olt' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'kapasitas_port_olt': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 14355 nilai di 'kapasitas_port_olt' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'kapasitas_port_olt' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'olt_port': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 8233 nilai di 'olt_port' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'olt_port' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'jumlah_splitter_fdt': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 11746 nilai di 'jumlah_splitter_fdt' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'jumlah_splitter_fdt' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'kapasitas_splitter_fdt': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 5937 nilai di 'kapasitas_splitter_fdt' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'kapasitas_splitter_fdt' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'port_fdt': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 16174 nilai di 'port_fdt' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'port_fdt' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'jumlah_splitter_fat': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 8780 nilai di 'jumlah_splitter_fat' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'jumlah_splitter_fat' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'kapasitas_splitter_fat': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 148 nilai di 'kapasitas_splitter_fat' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'kapasitas_splitter_fat' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'hc_old': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 11497 nilai di 'hc_old' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'hc_old' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'hc_icrm': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 13366 nilai di 'hc_icrm' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'hc_icrm' ke Int64 selesai.\n",
            " ¬†-> Memproses kolom 'total_hc': Membersihkan dan konversi ke Int64.\n",
            " ¬† ¬†‚ö†Ô∏è Terdapat 27 nilai di 'total_hc' yang awalnya tidak kosong namun diubah menjadi kosong (NaN).\n",
            " ¬† ¬†‚úÖ Pembersihan dan konversi 'total_hc' ke Int64 selesai.\n",
            "\n",
            " ¬†--- Mengonversi Kolom Lainnya ---\n",
            " ¬† ¬†‚ö†Ô∏è Kolom berikut tidak ditemukan di aset_data dan dilewati dalam konversi tipe data umum: ['Koordinat_olt']\n",
            " ¬†-> Mengonversi tipe data kolom aset_data lainnya menggunakan astype...\n",
            " ¬†‚úÖ Konversi tipe data aset_data (selain Int64 yang sudah ditangani) selesai.\n",
            "\n",
            "--- Memproses user_data ---\n",
            " ¬†-> Mengonversi kolom user_data...\n",
            " ¬† ¬†‚ö†Ô∏è Kolom berikut tidak ditemukan di user_data dan dilewati dalam konversi tipe data: ['fdt']\n",
            " ¬†‚úÖ Konversi tipe data user_data selesai.\n",
            "\n",
            "üìã Info aset_data setelah konversi:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 51 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   pa                      38968 non-null  string        \n",
            " 1   tanggal_rfs             21061 non-null  datetime64[ns]\n",
            " 2   mitra                   38968 non-null  string        \n",
            " 3   kategori                38968 non-null  string        \n",
            " 4   area_kp                 38968 non-null  string        \n",
            " 5   kota_kab                38968 non-null  string        \n",
            " 6   lokasi_olt              38968 non-null  object        \n",
            " 7   hostname_olt            38968 non-null  string        \n",
            " 8   koordinat_olt           38968 non-null  object        \n",
            " 9   brand_olt               38968 non-null  string        \n",
            " 10  type_olt                38968 non-null  string        \n",
            " 11  kapasitas_olt           34421 non-null  Int64         \n",
            " 12  kapasitas_port_olt      24613 non-null  Int64         \n",
            " 13  olt_port                30735 non-null  Int64         \n",
            " 14  interface_olt           38968 non-null  string        \n",
            " 15  fdt_new_existing        38968 non-null  string        \n",
            " 16  fdt_id                  38968 non-null  string        \n",
            " 17  jumlah_splitter_fdt     27222 non-null  Int64         \n",
            " 18  kapasitas_splitter_fdt  33031 non-null  Int64         \n",
            " 19  koordinat_fdt           38968 non-null  string        \n",
            " 20  port_fdt                22794 non-null  Int64         \n",
            " 21  status_osp_amarta_fdt   38968 non-null  string        \n",
            " 22  cluster                 38968 non-null  string        \n",
            " 23  koordinat_cluster       38968 non-null  string        \n",
            " 24  fat_id                  38968 non-null  string        \n",
            " 25  jumlah_splitter_fat     30188 non-null  Int64         \n",
            " 26  kapasitas_splitter_fat  38820 non-null  Int64         \n",
            " 27  koordinat_fat           38968 non-null  string        \n",
            " 28  status_osp_amarta_fat   38968 non-null  string        \n",
            " 29  kecamatan               38968 non-null  string        \n",
            " 30  kelurahan               38968 non-null  string        \n",
            " 31  sumber_datek            38968 non-null  string        \n",
            " 32  hc_old                  27471 non-null  Int64         \n",
            " 33  hc_icrm                 25602 non-null  Int64         \n",
            " 34  total_hc                38941 non-null  Int64         \n",
            " 35  cleansing_hp            38968 non-null  string        \n",
            " 36  olt                     38968 non-null  string        \n",
            " 37  update_aset             38968 non-null  string        \n",
            " 38  fat_kondisi             38968 non-null  string        \n",
            " 39  filter_fat_cap          38968 non-null  string        \n",
            " 40  fat_id_x                38968 non-null  string        \n",
            " 41  fat_filter_pemakaian    38968 non-null  string        \n",
            " 42  keterangan_full         38968 non-null  string        \n",
            " 43  amarta_update           38968 non-null  string        \n",
            " 44  link_dokumen_feeder     38968 non-null  string        \n",
            " 45  keterangan_dokumen      38968 non-null  string        \n",
            " 46  link_data_aset          38968 non-null  string        \n",
            " 47  keterangan_data_aset    38968 non-null  string        \n",
            " 48  link_maps               38968 non-null  string        \n",
            " 49  up3                     38968 non-null  string        \n",
            " 50  ulp                     38968 non-null  string        \n",
            "dtypes: Int64(11), datetime64[ns](1), object(2), string(37)\n",
            "memory usage: 15.9+ MB\n",
            " ¬† -> Tipe data kolom 'tanggal_rfs': datetime64[ns]\n",
            " ¬† -> Tipe data kolom 'kapasitas_olt': Int64\n",
            " ¬† -> Tipe data kolom 'kapasitas_port_olt': Int64\n",
            " ¬† -> Tipe data kolom 'olt_port': Int64\n",
            " ¬† -> Tipe data kolom 'jumlah_splitter_fdt': Int64\n",
            " ¬† -> Tipe data kolom 'hc_old': Int64\n",
            "\n",
            "üìã Info user_data setelah konversi:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 139016 entries, 5167 to 148442\n",
            "Data columns (total 7 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   sid                  139016 non-null  string\n",
            " 1   id_permohonan        139016 non-null  string\n",
            " 2   koordinat_pelanggan  139016 non-null  string\n",
            " 3   cust_name            139016 non-null  string\n",
            " 4   telpn                139016 non-null  string\n",
            " 5   fat_id               139016 non-null  string\n",
            " 6   notes                139016 non-null  string\n",
            "dtypes: string(7)\n",
            "memory usage: 8.5 MB\n",
            "\n",
            "‚úÖ Proses konversi tipe data selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np # Import numpy untuk np.nan\n",
        "# from decimal import Decimal # Asumsi ini tidak diperlukan jika hanya konversi ke float\n",
        "\n",
        "# ========================= Cleansing Functions =========================\n",
        "\n",
        "def clean_degree_with_comma(coord):\n",
        "    if pd.isna(coord) or '√Ç,' not in str(coord):\n",
        "        return None\n",
        "    coord = str(coord).replace('√Ç', '')\n",
        "    # Setelah hapus √Ç, mungkin format jadi lat,lon. Coba standardisasi dengan clean_comma_separated\n",
        "    return clean_comma_separated(coord) # Rantai ke fungsi lain yang lebih umum\n",
        "\n",
        "def clean_degree_separated(coord):\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "    coord_str = str(coord)\n",
        "    if '√Ç¬∞' not in coord_str:\n",
        "        return None\n",
        "    try:\n",
        "        # Contoh: -7.361902√Ç¬∞112.693948√Ç¬∞\n",
        "        # Temukan √Ç¬∞ pertama, pisahkan. Buang semua √Ç¬∞. Sisipkan koma.\n",
        "        parts = coord_str.split('√Ç¬∞')\n",
        "        if len(parts) >= 2:\n",
        "             lat_part = parts[0].strip()\n",
        "             lon_part = parts[1].strip().replace('√Ç¬∞','') # Hapus √Ç¬∞ sisa di lon\n",
        "             # Coba standardisasi dengan clean_comma_separated (jika lat/lon masih ada koma/titik desimal beda)\n",
        "             return clean_comma_separated(f\"{lat_part},{lon_part}\")\n",
        "    except:\n",
        "         pass\n",
        "    return None\n",
        "\n",
        "def clean_degree_as_separator(coord):\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "    coord_str = str(coord)\n",
        "    if '¬∞' not in coord_str:\n",
        "        return None\n",
        "    try:\n",
        "        # Contoh: -6.9271¬∞ 107.6048¬∞\n",
        "        # Temukan ¬∞ pertama, pisahkan. Buang semua ¬∞. Sisipkan koma.\n",
        "        parts = coord_str.split('¬∞')\n",
        "        if len(parts) >= 2:\n",
        "            lat_part = parts[0].strip()\n",
        "            lon_part = ''.join(parts[1:]).strip() # Gabungkan sisa part jika ada banyak ¬∞, strip\n",
        "            # Coba standardisasi dengan clean_comma_separated\n",
        "            return clean_comma_separated(f\"{lat_part},{lon_part}\")\n",
        "    except:\n",
        "         pass\n",
        "    return None\n",
        "\n",
        "def clean_two_commas_with_space(coord):\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "    coord_str = str(coord).strip()\n",
        "    # Contoh: -8,1948403, 111,1077904 atau -7,2892906 112,7276532\n",
        "    # Pola: AngkaDesimalKoma Spasi AngkaDesimalKoma ATAU AngkaDesimalKoma, Spasi AngkaDesimalKoma\n",
        "    # Kita bisa gabungkan dan standardisasi dengan clean_comma_separated\n",
        "    coord_str_standardized = coord_str.replace(', ', ',').replace(' ', ',') # Ganti ' ' atau ', ' jadi ','\n",
        "    return clean_comma_separated(coord_str_standardized)\n",
        "\n",
        "\n",
        "def clean_comma_separated(coord):\n",
        "    \"\"\"Handles standard 'lat,lon' format and standardizes decimal comma/dot.\"\"\"\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "    coord_str = str(coord).strip()\n",
        "    if ',' not in coord_str: # Harus ada setidaknya 1 koma sebagai pemisah\n",
        "         return None\n",
        "    parts = [part.strip() for part in coord_str.split(',', 1)] # Split hanya pada koma pertama\n",
        "    if len(parts) == 2:\n",
        "        lat_part = parts[0].replace(',', '.') # Standardisasi: desimal selalu titik\n",
        "        lon_part = parts[1].replace(',', '.') # Standardisasi: desimal selalu titik\n",
        "        # Cek apakah kedua part terlihat seperti angka setelah standardisasi\n",
        "        try:\n",
        "            float(lat_part)\n",
        "            float(lon_part)\n",
        "            return f\"{lat_part},{lon_part}\" # Kembalikan format standar \"lat,lon\"\n",
        "        except ValueError:\n",
        "             return None # Jika tidak bisa diubah jadi float, format salah\n",
        "    return None # Jika split tidak menghasilkan 2 part\n",
        "\n",
        "\n",
        "# Tambahkan fungsi baru untuk format titik-spasi\n",
        "def clean_dot_space_separated(coord):\n",
        "    \"\"\"Handles format like '-7.90845. 113.35127' -> '-7.90845,113.35127'\"\"\"\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "    coord_str = str(coord).strip()\n",
        "    if coord_str == '': return None\n",
        "\n",
        "    # Regex to match format like Number. Space(s) Number\n",
        "    # Allows optional minus at start, numbers, optional dot, numbers after dot.\n",
        "    # Captures the two numeric parts separated by dot and one or more spaces.\n",
        "    match = re.match(r'^(-?\\d+\\.?\\d*)\\.\\s+(\\-?\\d+\\.?\\d*)$', coord_str)\n",
        "    if match:\n",
        "        lat_part = match.group(1)\n",
        "        lon_part = match.group(2)\n",
        "        # Parts should already use '.' as decimal due to regex.\n",
        "        return f\"{lat_part},{lon_part}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def clean_dot_separated_no_comma(coord):\n",
        "    \"\"\"Handles format like 'X.Y.A.B' or 'X.YYYYYYY.AAAAAAA' -> 'X.Y,A.B'\"\"\"\n",
        "    if pd.isna(coord): return None\n",
        "    coord_str = str(coord).strip()\n",
        "    if ',' in coord_str: return None # Jangan proses jika ada koma\n",
        "\n",
        "    # Coba regex yang mencari pola Angka.Angka.Angka.Angka atau Angka.Angka.Angka\n",
        "    # Regex: Angka (opsional -) diikuti . diikuti Angka, kemudian . Angka (opsional . Angka lagi di akhir)\n",
        "    # Ini mencoba menangani beberapa pola titik sebagai pemisah utama\n",
        "    match = re.match(r'^(-?\\d+\\.?\\d*)\\.(\\d+\\.?\\d*)\\.?(\\d*\\.?\\d*)$', coord_str)\n",
        "    if match:\n",
        "        # Jika match, kita asumsikan split utamanya adalah setelah titik pertama\n",
        "        lat_part = match.group(1) # Ini harusnya Lat integer + desimal\n",
        "        # Gabungkan group 2 dan 3 sebagai Lon\n",
        "        lon_part = match.group(2) # Ini harusnya Lon integer + desimal\n",
        "        if match.group(3): # Jika ada group ke-3 (dari pola X.Y.A.B.C)\n",
        "             # Pola X.Y.A.B.C mungkin A.B lat, C.D lon\n",
        "             # Atau X.Y lat, A.B.C lon -> ini rumit\n",
        "             # Berdasarkan contoh \"-7.36271456342.732918\" -> \"-7.362714,112.732918\"\n",
        "             # Ini bukan pola A.B.C.D.\n",
        "             # Mari fokus pada pola X.Y.A.B -> X.Y,A.B\n",
        "             # Asumsi regex ^(-?\\d+\\.?\\d*)\\.(\\d+\\.?\\d*)$ lebih relevan untuk pola dua bagian dipisah titik\n",
        "             # Kita pakai regex spesifik ^(-?\\d+\\.\\d+)\\.(\\d+\\.?\\d+)$ seperti di clean_dot_space_separated tapi tanpa spasi\n",
        "             match_simple_dot_sep = re.match(r'^(-?\\d+\\.\\d+)\\.(\\d+\\.?\\d*)$', coord_str)\n",
        "             if match_simple_dot_sep:\n",
        "                 lat_part = match_simple_dot_sep.group(1)\n",
        "                 lon_part = match_simple_dot_sep.group(2)\n",
        "                 return clean_comma_separated(f\"{lat_part},{lon_part}\") # Standardisasi via clean_comma_separated\n",
        "\n",
        "\n",
        "    return None # Jika tidak cocok pola titik sebagai pemisah utama tanpa koma\n",
        "\n",
        "\n",
        "def clean_merged_coordinates(coord):\n",
        "    \"\"\"Handles formats like -7.36271456342.732918 (jika ada pola khusus) atau -8180339111.116929\"\"\"\n",
        "    if pd.isna(coord): return None\n",
        "    coord_str = str(coord).strip().replace(\" \", \"\").replace(\",\", \"\") # Hapus spasi dan koma\n",
        "\n",
        "    # Contoh: -8180339111.116929\n",
        "    # Regex: mulai negatif opsional, digit (lat integer+decimal), digit (lon integer), titik (decimal), digit (lon decimal)\n",
        "    # Pola di regex asli: ^(-?\\d+\\.\\d+)(\\d{3}\\.\\d+)$ cocok untuk A.B C.D dimana C 3 digit.\n",
        "    # Untuk -8180339111.116929, format ini mungkin dari konversi float besar.\n",
        "    # Pola raw_data -8180339111.116929 -> harus jadi -8.180339,111.116929\n",
        "    # Ini diproses oleh clean_split_from_long_float jika inputnya float/int.\n",
        "    # Jika inputnya string \"-8180339111.116929\", clean_split_from_long_float akan return None.\n",
        "    # Regex yang mungkin cocok string ini: ^(-?\\d+)(\\d{3}\\.?\\d*)\\.(\\d+\\.?\\d*)$\n",
        "    match_big_number = re.match(r'^(-?\\d+)(\\d{3}\\.?\\d*)\\.(\\d+\\.?\\d*)$', coord_str)\n",
        "    if match_big_number:\n",
        "         # Ini mungkin bukan format lat,lon yang sebenarnya.\n",
        "         # Pola -8180339111.116929 => -8 (lat int) 180339 (lat dec) 111 (lon int) 116929 (lon dec)\n",
        "         # Regex: ^(-?\\d)(\\d+)(\\d{3})\\.(\\d+)$\n",
        "         match_specific_merged = re.match(r'^(-?\\d)(\\d+)(\\d{3})\\.(\\d+)$', coord_str)\n",
        "         if match_specific_merged:\n",
        "              lat_int = match_specific_merged.group(1)\n",
        "              lat_dec = match_specific_merged.group(2)\n",
        "              lon_int = match_specific_merged.group(3)\n",
        "              lon_dec = match_specific_merged.group(4)\n",
        "              # Format menjadi -LatInt.LatDec,LonInt.LonDec\n",
        "              return f\"{lat_int}.{lat_dec},{lon_int}.{lon_dec}\"\n",
        "         # Jika tidak cocok pola spesifik ini, biarkan regex asli jika masih relevan\n",
        "         match = re.match(r'^(-?\\d+\\.\\d+)(\\d{3}\\.\\d+)$', coord_str) # Regex asli\n",
        "         if match:\n",
        "             lat = match.group(1)\n",
        "             lon = match.group(2)\n",
        "             return f\"{lat},{lon}\" # Kembalikan format standar lat,lon\n",
        "\n",
        "    return None # Jika tidak cocok pola gabungan\n",
        "\n",
        "\n",
        "def move_comma_separator(coord):\n",
        "    # Ini terlihat seperti logika kompleks untuk format spesifik, biarkan seperti adanya.\n",
        "    if pd.isna(coord) or ',' not in str(coord) or str(coord).count('.') != 2:\n",
        "        return None\n",
        "    try:\n",
        "        # Contoh: 7.123.456,112.789.012 -> 7.123456,112.789012 (ini asumsi saya)\n",
        "        # Kode asli Anda sepertinya memindahkan bagian setelah desimal pertama ke Lon\n",
        "        # lat_part, lon_part = str(coord).split(',')\n",
        "        # lat_before, lat_after = lat_part.split('.') # lat_before='7', lat_after='123.456' -> error di sini\n",
        "        # Ini logicnya perlu disesuaikan dengan format persisnya.\n",
        "        # Biarkan fungsi ini seperti aslinya jika memang menangani format spesifik.\n",
        "        # Jika contoh raw_data \"8.180339,111.116929\" ini yang dimaksud, itu ditangani clean_comma_separated\n",
        "        # Jika contoh \"7.123.456,112.789.012\" yang dimaksud, regex di clean_dot_separated_no_comma mungkin lebih pas jika koma dihilangkan\n",
        "        pass # Biarkan logika asli atau kembalikan None jika tidak yakin\n",
        "    except:\n",
        "        pass\n",
        "    return None # Kembalikan None karena logikanya rumit dan rentan error\n",
        "\n",
        "def clean_with_e_separator(coord):\n",
        "    # Ini terlihat sudah menangani format E, biarkan seperti adanya.\n",
        "    if pd.isna(coord): return None\n",
        "    coord_str = str(coord).strip()\n",
        "    if 'E' not in coord_str: return None\n",
        "    try:\n",
        "        # Contoh: -7.86482E112.69473 atau S709.168E11224.693\n",
        "        # Split by 'E'\n",
        "        parts = coord_str.split('E')\n",
        "        if len(parts) == 2:\n",
        "            lat_part = parts[0].strip()\n",
        "            lon_part = parts[1].strip()\n",
        "\n",
        "            # Tangani S/N di Latitude\n",
        "            is_south = False\n",
        "            if lat_part.upper().startswith('S'):\n",
        "                 is_south = True\n",
        "                 lat_part = lat_part[1:].strip() # Hapus 'S'\n",
        "\n",
        "            # Asumsi format sebelum E adalah angka desimal (X.Y) atau integer (X)\n",
        "            # Asumsi format setelah E adalah angka desimal (A.B) atau integer (A)\n",
        "            # Konversi ke float untuk validasi dan standardisasi (jika perlu penyesuaian skala seperti di kode asli)\n",
        "            try:\n",
        "                 lat_float = float(lat_part)\n",
        "                 lon_float = float(lon_part)\n",
        "\n",
        "                 # Jika ada logika penyesuaian skala seperti \"/ 100\" di kode asli, terapkan di sini\n",
        "                 # Contoh: S709.168 -> 7.09168 (geser koma 2 tempat)\n",
        "                 # Asumsi 709.168E11224.693 -> 7.09168, 112.24693 (geser koma 2 tempat untuk lat dan 3 untuk lon?)\n",
        "                 # Logika asli Anda: lat/100, lon/100. Mari pertahankan jika itu intentnya.\n",
        "                 # Ini mungkin tergantung format persis sebelum E.\n",
        "                 # Mari kembalikan nilai float, lalu biarkan konversi akhir menangani float ke string.\n",
        "                 # Atau kembalikan string \"lat,lon\" dengan float format\n",
        "                 lat_final = lat_float / 100 if abs(lat_float) > 90 else lat_float # Contoh heuristic: jika >90, geser koma\n",
        "                 lon_final = lon_float / 100 if abs(lon_float) > 180 else lon_float # Contoh heuristic: jika >180, geser koma\n",
        "                 # Logika asli Anda hanya bagi 100. Mari pertahankan jika itu polanya.\n",
        "                 lat_final = lat_float / 100\n",
        "                 lon_final = lon_float / 100\n",
        "\n",
        "                 if is_south:\n",
        "                     lat_final = -abs(lat_final) # Pastikan negatif jika 'S'\n",
        "\n",
        "                 # Kembalikan sebagai string \"lat,lon\"\n",
        "                 return f\"{lat_final},{lon_final}\"\n",
        "\n",
        "            except ValueError:\n",
        "                 return None # Jika partnya bukan angka\n",
        "\n",
        "    except:\n",
        "         pass\n",
        "    return None\n",
        "\n",
        "\n",
        "def clean_split_from_long_float(coord):\n",
        "    \"\"\"Handles large raw float/int numbers like -8180339111.116929 -> -8.180339,111.116929\"\"\"\n",
        "    # Ini adalah kasus spesifik jika data awalnya berupa angka float atau int yang besar\n",
        "    try:\n",
        "        # Cek apakah input adalah float atau int, BUKAN string\n",
        "        if not isinstance(coord, (float, int)) or pd.isna(coord):\n",
        "            return None\n",
        "\n",
        "        # Ubah angka menjadi string dengan presisi tinggi, buang titik desimal, buang minus di awal jika ada\n",
        "        # Contoh: -8180339111.116929 -> \"-8180339111.11692900000000\" -> \"818033911111692900000000\"\n",
        "        # Sesuaikan format presisi sesuai data Anda\n",
        "        coord_str_raw = \"{:.10f}\".format(coord).replace('.', '').replace('-', '')\n",
        "        # Hapus nol di belakang jika ada (misal .000)\n",
        "        coord_str = coord_str_raw.rstrip('0')\n",
        "\n",
        "        if len(coord_str) < 10: # Heuristic: Asumsi lat+lon punya total digit minimal segini\n",
        "             return None # Angka terlalu kecil untuk pola gabungan ini\n",
        "\n",
        "        # Pola: -LatInt LatDec LonInt LonDec\n",
        "        # -8.180339,111.116929\n",
        "        # Lat: -8 (1 digit) . 180339 (6 digit)\n",
        "        # Lon: 111 (3 digit) . 116929 (6 digit)\n",
        "        # Total digit (tanpa minus dan titik): 1 + 6 + 3 + 6 = 16 digit\n",
        "        # Jika pola selalu LatInt(1).LatDec(6)LonInt(3).LonDec(>=1)\n",
        "        # Cari 6 digit setelah digit pertama (integer lat) sebagai lat desimal\n",
        "        # Cari 3 digit setelah lat desimal sebagai lon integer\n",
        "        # Sisanya adalah lon desimal\n",
        "        # string gabungan: -8 180339 111 116929\n",
        "        # index: 0  1..6   7..9 10..akhir\n",
        "        # Lengths: 1, 6, 3, ?\n",
        "        # Check panjang string: minimal 10 (1+6+3)\n",
        "        if len(coord_str) < 10:\n",
        "             return None\n",
        "\n",
        "        try:\n",
        "             lat_int_digit = coord_str[0] # Asumsi 1 digit integer lat (setelah hapus minus)\n",
        "             lat_dec_digits = coord_str[1:7] # Asumsi 6 digit desimal lat\n",
        "             lon_int_digits = coord_str[7:10] # Asumsi 3 digit integer lon\n",
        "             lon_dec_digits = coord_str[10:] # Sisa adalah desimal lon\n",
        "\n",
        "             # Rekonstruksi string \"lat,lon\"\n",
        "             lat = f\"-{lat_int_digit}.{lat_dec_digits}\" # Tambahkan kembali minus jika awal negatif\n",
        "             lon = f\"{lon_int_digits}.{lon_dec_digits}\"\n",
        "\n",
        "             # Cek apakah angka asli negatif\n",
        "             if coord < 0:\n",
        "                  lat = f\"-{lat_int_digit}.{lat_dec_digits}\" # Tambahkan kembali minus\n",
        "\n",
        "             # Final standardisasi dan validasi\n",
        "             return clean_comma_separated(f\"{lat},{lon}\")\n",
        "\n",
        "        except IndexError:\n",
        "             return None # String tidak cukup panjang untuk pola\n",
        "\n",
        "\n",
        "    except:\n",
        "        # Tangani error lain jika format float/int tidak seperti yang diharapkan\n",
        "        pass # Fall through\n",
        "\n",
        "    return None # Jika input bukan float/int atau pola tidak cocok\n",
        "\n",
        "\n",
        "# --- Fungsi clean_comma_separated yang Dimodifikasi ---\n",
        "def clean_comma_separated(coord):\n",
        "    \"\"\"\n",
        "    Handles standard 'lat,lon' format, standardizes decimal comma/dot,\n",
        "    and removes multiple consecutive dots (e.g., '..').\n",
        "    \"\"\"\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "    coord_str = str(coord).strip()\n",
        "    if ',' not in coord_str: # Harus ada setidaknya 1 koma sebagai pemisah\n",
        "         return None\n",
        "    # Split hanya pada koma pertama untuk memisahkan lat dan lon\n",
        "    parts = [part.strip() for part in coord_str.split(',', 1)]\n",
        "    if len(parts) == 2:\n",
        "        lat_part = parts[0].replace(',', '.') # Standardisasi: desimal selalu titik\n",
        "        lon_part = parts[1].replace(',', '.') # Standardisasi: desimal selalu titik\n",
        "\n",
        "        # --- PENTING: Hapus titik berurutan di sini ---\n",
        "        # Ganti satu atau lebih titik berurutan (\\.+) dengan satu titik (.)\n",
        "        lat_part = re.sub(r'\\.+', '.', lat_part)\n",
        "        lon_part = re.sub(r'\\.+', '.', lon_part)\n",
        "\n",
        "        # Pastikan tidak ada titik di awal atau akhir setelah penggantian\n",
        "        lat_part = lat_part.strip('.')\n",
        "        lon_part = lon_part.strip('.')\n",
        "        # --- End of Added Step ---\n",
        "\n",
        "        # Cek apakah kedua part terlihat seperti angka setelah standardisasi dan pembersihan titik\n",
        "        try:\n",
        "            float(lat_part)\n",
        "            float(lon_part)\n",
        "            return f\"{lat_part},{lon_part}\" # Kembalikan format standar \"lat,lon\" string\n",
        "        except ValueError:\n",
        "             return None # Jika tidak bisa diubah jadi float, format salah\n",
        "    return None # Jika split tidak menghasilkan 2 part\n",
        "\n",
        "# --- Fungsi apply_cleaning (Tetap sama, karena memanggil clean_comma_separated) ---\n",
        "def apply_cleaning(coord):\n",
        "    \"\"\"\n",
        "    Proses data latitude/longitude untuk numerik dan string,\n",
        "    mencoba berbagai format pembersihan, mengembalikan string format \"lat,lon\" atau None.\n",
        "    \"\"\"\n",
        "    # Langkah 1: Tangani input None/NaN langsung\n",
        "    if pd.isna(coord):\n",
        "        return None\n",
        "\n",
        "    # Langkah 2: Coba format yang inputnya mungkin berupa angka mentah (float/int)\n",
        "    cleaned_coord = clean_split_from_long_float(coord)\n",
        "    if cleaned_coord is not None:\n",
        "        return cleaned_coord\n",
        "\n",
        "    # Langkah 3: Jika input bukan angka atau clean_split_from_long_float gagal, coba sebagai string\n",
        "    coord_str_raw = str(coord)\n",
        "    # ** PENTING: Hapus karakter problematic (√Ç, NBSP) di awal **\n",
        "    coord_str = coord_str_raw.replace('√Ç', '').replace('\\u00A0', ' ').strip()\n",
        "\n",
        "    # Tangani string kosong atau representasi null dalam string setelah pembersihan awal\n",
        "    if coord_str == '' or coord_str.lower() in ['none', 'nan', '<na>']:\n",
        "        return None\n",
        "\n",
        "    # Coba fungsi pembersihan berbasis string dalam urutan yang logis\n",
        "    # Fungsi yang lebih spesifik atau yang menangani pemisah non-standar didahulukan\n",
        "    cleaned_coord = (\n",
        "        # clean_degree_with_comma(coord_str) # Dihapus\n",
        "        # clean_degree_separated(coord_str) # Dihapus\n",
        "        clean_degree_as_separator(coord_str) or # Ex: -6.9271¬∞ 107.6048¬∞\n",
        "        clean_two_commas_with_space(coord_str) or # Ex: -8,1948403, 111,1077904\n",
        "        clean_dot_space_separated(coord_str) or # Ex: -7.90845. 113.35127\n",
        "        clean_with_e_separator(coord_str) or # Ex: -7.86482E112.69473\n",
        "        clean_dot_separated_no_comma(coord_str) or # Ex: -7.90845.113.35127\n",
        "        clean_merged_coordinates(coord_str) or # Ex: -7.362714563.427329\n",
        "        move_comma_separator(coord_str) # Ex: 7.123.456,112.789.012\n",
        "        # clean_comma_separated tidak dipanggil di sini agar hanya menjadi fallback\n",
        "    )\n",
        "\n",
        "    if cleaned_coord is not None:\n",
        "        # Jika salah satu fungsi pembersih spesifik berhasil, ia mengembalikan string \"lat,lon\"\n",
        "        return cleaned_coord\n",
        "\n",
        "    # Langkah 4: Fallback terakhir - coba split koma jika ada koma\n",
        "    # Ini menangani format standar \"lat,lon\" atau kasus lain yang setelah pembersihan awal\n",
        "    # menghasilkan string dengan koma sebagai pemisah utama (termasuk \"-7.331868..,112.637920\").\n",
        "    if ',' in coord_str:\n",
        "        # Gunakan logika clean_comma_separated (yang sudah dimodifikasi)\n",
        "        return clean_comma_separated(coord_str)\n",
        "\n",
        "\n",
        "    # Langkah 5: Jika tidak ada format yang cocok sama sekali\n",
        "    return None\n",
        "\n",
        "\n",
        "# ========================= Contoh Data (Tambahkan kasus baru) =========================\n",
        "raw_data = [\n",
        "    \"-7.361902√Ç,112.693948√Ç\", # Ini data asli, setelah √Ç dihapus -> \"-7.361902,112.693948\"\n",
        "    \"-7.361902√Ç¬∞112.693948√Ç¬∞\", # setelah √Ç dihapus -> \"-7.361902¬∞112.693948¬∞\"\n",
        "    \"-6.9271¬∞ 107.6048¬∞\",\n",
        "    \"-8,1948403, 111,1077904\",\n",
        "    \"8.180339,111.116929\",\n",
        "    \"-7,2892906 112,7276532\",\n",
        "    \"-7.36271456342.732918\",\n",
        "    -8180339111.116929,\n",
        "    \"-7.86482E112.69473\",\n",
        "    \"S709.168E11224.693\",\n",
        "    \"-7.90845. 113.35127\",\n",
        "    \"  -5.123 . 110.456 \",\n",
        "    \"1.2.3.4.5\",\n",
        "    \"abc\",\n",
        "    \"123\",\n",
        "    \"123,abc\",\n",
        "    \"123.45,abc.def\",\n",
        "    None, np.nan, \"\", \" \", \"<NA>\",\n",
        "    # --- Kasus baru yang ingin ditangani ---\n",
        "    \"-7.331868..,112.637920\", # Kasus double dot\n",
        "    \"-7.331868...,112.637920\", # Kasus triple dot\n",
        "    \"-7..331868,112.637920\", # Kasus double dot di tempat lain (setelah minus)\n",
        "    \"8.123..,110.456..\", # Kasus double dot di kedua sisi\n",
        "    \"1...2...3,4...5...6\" # Kasus banyak titik di kedua sisi\n",
        "]\n",
        "\n",
        "# ========================= Proses Data =========================\n",
        "print(\"Memproses data contoh...\")\n",
        "cleaned_data = [apply_cleaning(coord) for coord in raw_data]\n",
        "\n",
        "# ========================= Output =========================\n",
        "print(\"\\nOriginal -> Cleaned (string format 'lat,lon' atau None)\")\n",
        "print(\"=\" * 60)\n",
        "for i, (original, cleaned) in enumerate(zip(raw_data, cleaned_data), 1):\n",
        "    # Gunakan repr() atau !r untuk menampilkan string secara literal (termasuk '', None)\n",
        "    print(f\"{i}. Original: {original!r}\")\n",
        "    print(f\" ¬† ‚úÖ Cleaned : {cleaned!r}\")\n",
        "    # Opsional: Cek apakah hasil cleaned bisa dipecah dan diubah jadi float\n",
        "    if isinstance(cleaned, str) and ',' in cleaned:\n",
        "        try:\n",
        "            lat, lon = cleaned.split(',', 1)\n",
        "            lat_float = float(lat)\n",
        "            lon_float = float(lon)\n",
        "            print(f\" ¬† -> Hasil OK, siap konversi Float. Lat: {lat_float}, Lon: {lon_float}\")\n",
        "        except (ValueError, TypeError):\n",
        "            print(\" ¬† !!! Peringatan: Hasil clean tidak bisa dikonversi jadi Float! !!!\")\n",
        "    elif cleaned is None:\n",
        "         print(\" ¬† -> Hasil adalah None (tidak dikenali).\")\n",
        "    else:\n",
        "         print(f\" ¬† !!! Peringatan: Hasil clean bukan string 'lat,lon' atau None! ({type(cleaned)}) !!!\")\n",
        "\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT9VSIMJ4VsQ",
        "outputId": "86f3fe1d-49c5-45e7-baa1-3fcca44ce466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memproses data contoh...\n",
            "\n",
            "Original -> Cleaned (string format 'lat,lon' atau None)\n",
            "============================================================\n",
            "1. Original: '-7.361902√Ç,112.693948√Ç'\n",
            " ¬† ‚úÖ Cleaned : '-7.361902,112.693948'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.361902, Lon: 112.693948\n",
            "2. Original: '-7.361902√Ç¬∞112.693948√Ç¬∞'\n",
            " ¬† ‚úÖ Cleaned : '-7.361902,112.693948'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.361902, Lon: 112.693948\n",
            "3. Original: '-6.9271¬∞ 107.6048¬∞'\n",
            " ¬† ‚úÖ Cleaned : '-6.9271,107.6048'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -6.9271, Lon: 107.6048\n",
            "4. Original: '-8,1948403, 111,1077904'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "5. Original: '8.180339,111.116929'\n",
            " ¬† ‚úÖ Cleaned : '8.180339,111.116929'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: 8.180339, Lon: 111.116929\n",
            "6. Original: '-7,2892906 112,7276532'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "7. Original: '-7.36271456342.732918'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "8. Original: -8180339111.116929\n",
            " ¬† ‚úÖ Cleaned : '-8.180339,111.1169290543'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -8.180339, Lon: 111.1169290543\n",
            "9. Original: '-7.86482E112.69473'\n",
            " ¬† ‚úÖ Cleaned : '-0.0786482,1.1269473'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -0.0786482, Lon: 1.1269473\n",
            "10. Original: 'S709.168E11224.693'\n",
            " ¬† ‚úÖ Cleaned : '-7.09168,112.24692999999999'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.09168, Lon: 112.24692999999999\n",
            "11. Original: '-7.90845. 113.35127'\n",
            " ¬† ‚úÖ Cleaned : '-7.90845,113.35127'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.90845, Lon: 113.35127\n",
            "12. Original: '  -5.123 . 110.456 '\n",
            " ¬† ‚úÖ Cleaned : '-5.123,110.456'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -5.123, Lon: 110.456\n",
            "13. Original: '1.2.3.4.5'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "14. Original: 'abc'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "15. Original: '123'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "16. Original: '123,abc'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "17. Original: '123.45,abc.def'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "18. Original: None\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "19. Original: nan\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "20. Original: ''\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "21. Original: ' '\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "22. Original: '<NA>'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "23. Original: '-7.331868..,112.637920'\n",
            " ¬† ‚úÖ Cleaned : '-7.331868,112.637920'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.331868, Lon: 112.63792\n",
            "24. Original: '-7.331868...,112.637920'\n",
            " ¬† ‚úÖ Cleaned : '-7.331868,112.637920'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.331868, Lon: 112.63792\n",
            "25. Original: '-7..331868,112.637920'\n",
            " ¬† ‚úÖ Cleaned : '-7.331868,112.637920'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: -7.331868, Lon: 112.63792\n",
            "26. Original: '8.123..,110.456..'\n",
            " ¬† ‚úÖ Cleaned : '8.123,110.456'\n",
            " ¬† -> Hasil OK, siap konversi Float. Lat: 8.123, Lon: 110.456\n",
            "27. Original: '1...2...3,4...5...6'\n",
            " ¬† ‚úÖ Cleaned : None\n",
            " ¬† -> Hasil adalah None (tidak dikenali).\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_invalid_characters(value):\n",
        "    \"\"\"\n",
        "    Membersihkan simbol atau karakter tidak valid dari nilai latitude/longitude\n",
        "    tanpa membuatnya kosong atau NaN.\n",
        "    \"\"\"\n",
        "    if pd.isna(value):\n",
        "        return value\n",
        "    try:\n",
        "        return re.sub(r'[^\\d\\.,-]', '', str(value))\n",
        "    except Exception:\n",
        "        return value\n",
        "\n",
        "  # Validasi dan split ulang latitude_olt menjadi latitude_olt_clean dan longitude_olt_clean\n",
        "def validate_and_split(value):\n",
        "    \"\"\"\n",
        "    Memastikan bahwa data latitude_olt memiliki koma (,) untuk split.\n",
        "    Jika tidak, biarkan nilai original di latitude dan None untuk longitude.\n",
        "    \"\"\"\n",
        "    if pd.isna(value) or ',' not in value:\n",
        "        return pd.Series([value, None])  # Kembalikan latitude dan kosongkan longitude\n",
        "    try:\n",
        "        lat, lon = value.split(\",\", 1)\n",
        "        return pd.Series([lat.strip(), lon.strip()])  # Bersihkan spasi tambahan\n",
        "    except ValueError:\n",
        "        return pd.Series([value, None])  # Jika error, biarkan nilai original"
      ],
      "metadata": {
        "id": "6AeJtw134UWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========================= Cleansing Kolom Koordinat =========================\\n\")\n",
        "\n",
        "# Asumsi kolom 'koordinat_olt' ada\n",
        "if 'koordinat_olt' in aset_data.columns:\n",
        "    print(\"‚ÑπÔ∏è Memproses kolom 'koordinat_olt' (gabungan Latitude, Longitude)...\")\n",
        "    try:\n",
        "        # Langkah 1: Apply initial cleaning to the combined coordinate string\n",
        "        # apply_cleaning harus mengembalikan string atau nilai yang bisa di-astype(str)\n",
        "        # Kembalikan '' atau None/np.nan untuk nilai yang tidak valid\n",
        "        aset_data[\"koordinat_olt_cleaned\"] = aset_data[\"koordinat_olt\"].apply(apply_cleaning)\n",
        "        print(\"‚úÖ apply_cleaning pada 'koordinat_olt' selesai.\")\n",
        "\n",
        "        # Langkah 2: Split cleaned coordinate string into two new columns\n",
        "        # Gunakan .str.split(',', expand=True) untuk memecah string menjadi DataFrame 2 kolom\n",
        "        # Jika koordinat_olt_cleaned adalah None/NaN, .str.split akan menghasilkan NaN di kedua kolom.\n",
        "        # Jika koordinat_olt_cleaned adalah '', .str.split(',', expand=True) akan menghasilkan DataFrame dengan ['',''].\n",
        "        # Jika koordinat_olt_cleaned adalah 'hanya_lat' atau 'hanya_lon,', split akan menghasilkan 1 atau 2 kolom dengan ''/None\n",
        "        # Kita akan menugaskannya ke kolom target dan menanganinya di langkah pembersihan berikutnya.\n",
        "        split_coords = aset_data[\"koordinat_olt_cleaned\"].str.split(',', expand=True)\n",
        "        print(\"‚úÖ Split 'koordinat_olt_cleaned' selesai.\")\n",
        "\n",
        "        # Langkah 3: Tugaskan hasil split ke kolom target latitude_olt dan longitude_olt\n",
        "        # Method .str.split(expand=True) mengembalikan DataFrame baru.\n",
        "        # Kolom pertama hasil split adalah index 0, kolom kedua adalah index 1.\n",
        "        # Jika split menghasilkan kurang dari 2 kolom (misal input 'hanya_lat'),\n",
        "        # mengakses split_coords[1] akan menghasilkan kolom yang semuanya NaN.\n",
        "        # Jika split menghasilkan lebih dari 2 kolom (misal input 'a,b,c'), kolom sisanya akan diabaikan di sini.\n",
        "\n",
        "        # Inisialisasi kolom target dengan NaN jika belum ada atau untuk menimpa data lama\n",
        "        aset_data[\"latitude_olt\"] = np.nan\n",
        "        aset_data[\"longitude_olt\"] = np.nan\n",
        "\n",
        "        # Tugaskan kolom hasil split jika split_coords memiliki minimal 1 kolom\n",
        "        if split_coords.shape[1] > 0:\n",
        "             aset_data[\"latitude_olt\"] = split_coords[0]\n",
        "             print(\"‚úÖ Kolom 0 hasil split ditugaskan ke latitude_olt.\")\n",
        "\n",
        "        # Tugaskan kolom hasil split jika split_coords memiliki minimal 2 kolom\n",
        "        if split_coords.shape[1] > 1:\n",
        "             aset_data[\"longitude_olt\"] = split_coords[1]\n",
        "             print(\"‚úÖ Kolom 1 hasil split ditugaskan ke longitude_olt.\")\n",
        "        else:\n",
        "             print(\"‚ö†Ô∏è Split tidak menghasilkan 2 kolom, longitude_olt mungkin diisi NaN atau tidak berubah.\")\n",
        "\n",
        "\n",
        "        # Langkah 4: Lakukan pembersihan dan konversi akhir pada latitude_olt dan longitude_olt\n",
        "        # Nilai di sini adalah string (atau NaN jika split gagal atau input awal null)\n",
        "        # Mereka mungkin perlu pembersihan karakter, standardisasi desimal, dan konversi ke float\n",
        "\n",
        "        print(\"‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_olt dan longitude_olt.\")\n",
        "\n",
        "        # Pastikan kolom target adalah string untuk operasi selanjutnya\n",
        "        # Ini penting untuk menangani np.nan -> '<NA>' atau nilai lain menjadi string\n",
        "        aset_data[\"latitude_olt\"] = aset_data[\"latitude_olt\"].astype(str)\n",
        "        aset_data[\"longitude_olt\"] = aset_data[\"longitude_olt\"].astype(str)\n",
        "        print(\"‚úÖ latitude_olt dan longitude_olt diubah ke string.\")\n",
        "\n",
        "        # Tangani string representasi null yang mungkin ada setelah split dan astype(str)\n",
        "        # Termasuk '', '<NA>', 'None', dan string kosong setelah strip\n",
        "        aset_data[\"latitude_olt\"] = aset_data[\"latitude_olt\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        aset_data[\"longitude_olt\"] = aset_data[\"longitude_olt\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        print(\"‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\")\n",
        "\n",
        "        # Apply clean_invalid_characters jika dibutuhkan. Fungsi ini harus menangani string atau NaN.\n",
        "        # Perannya adalah membersihkan karakter *di dalam* string yang seharusnya berupa angka float.\n",
        "        # Pastikan clean_invalid_characters(np.nan) mengembalikan np.nan.\n",
        "        aset_data[\"latitude_olt\"] = aset_data[\"latitude_olt\"].apply(clean_invalid_characters)\n",
        "        aset_data[\"longitude_olt\"] = aset_data[\"longitude_olt\"].apply(clean_invalid_characters)\n",
        "        print(\"‚úÖ clean_invalid_characters selesai pada latitude_olt dan longitude_olt.\")\n",
        "\n",
        "        # Final conversion to float, coercing any remaining errors to NaN\n",
        "        # pd.to_numeric adalah cara paling tangguh untuk ini.\n",
        "        aset_data['latitude_olt'] = pd.to_numeric(aset_data['latitude_olt'], errors='coerce')\n",
        "        aset_data['longitude_olt'] = pd.to_numeric(aset_data['longitude_olt'], errors='coerce')\n",
        "        print(\"‚úÖ Konversi akhir ke float selesai pada latitude_olt dan longitude_olt.\")\n",
        "\n",
        "        # Hitung berapa banyak nilai non-null awal di koordinat_olt yang menghasilkan NaN di lat/lon\n",
        "        # Hitung jumlah NaN di kolom lat/lon hasil akhir\n",
        "        initial_coord_non_null = aset_data[\"koordinat_olt\"].notna().sum()\n",
        "        final_lat_null_count = aset_data[\"latitude_olt\"].isna().sum()\n",
        "        final_lon_null_count = aset_data[\"longitude_olt\"].isna().sum()\n",
        "        # Jumlah nilai yang *awalnya* di koordinat_olt tapi *akhirnya* jadi NaN di lat/lon (minimal salah satu)\n",
        "        # Ini agak kompleks dihitung tepat, tapi jumlah NaN akhir memberikan gambaran.\n",
        "        print(f\"‚ÑπÔ∏è Total baris: {len(aset_data)}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'koordinat_olt' non-kosong awal: {initial_coord_non_null}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'latitude_olt' yang menjadi kosong (NaN): {final_lat_null_count}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'longitude_olt' yang menjadi kosong (NaN): {final_lon_null_count}\")\n",
        "\n",
        "\n",
        "        # Drop the intermediate cleaned coordinate column if no longer needed\n",
        "        if \"koordinat_olt_cleaned\" in aset_data.columns:\n",
        "             aset_data.drop(columns=[\"koordinat_olt_cleaned\",\"koordinat_olt\"], inplace=True)\n",
        "\n",
        "             print(\"‚úÖ Kolom 'koordinat_olt_cleaned' dihapus.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error dalam proses cleansing koordinat OLT: {e}\")\n",
        "        # Jika terjadi error di sini, pastikan latitude_olt dan longitude_olt diisi NaN\n",
        "        # agar tidak error di langkah selanjutnya yang mungkin mengasumsikan kolom ini ada.\n",
        "        if \"latitude_olt\" not in aset_data.columns: aset_data[\"latitude_olt\"] = np.nan\n",
        "        if \"longitude_olt\" not in aset_data.columns: aset_data[\"longitude_olt\"] = np.nan\n",
        "        print(\"‚ö†Ô∏è Kolom latitude_olt dan longitude_olt mungkin tidak terproses sepenuhnya karena error.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kolom 'koordinat_olt' tidak ditemukan dalam aset_data. Melewatkan cleansing koordinat OLT.\")\n",
        "\n",
        "# Output informasi\n",
        "print(\"\\nüìã Info aset_data setelah cleansing koordinat:\")\n",
        "aset_data.info()\n",
        "\n",
        "# Mencetak info hanya untuk kolom tertentu\n",
        "if 'latitude_olt' in aset_data.columns and 'longitude_olt' in aset_data.columns:\n",
        "    print(\"\\nüìã Info kolom 'latitude_olt' dan 'longitude_olt' setelah cleansing:\")\n",
        "    print(aset_data[['latitude_olt', 'longitude_olt']].info())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Kolom 'latitude_olt' atau 'longitude_olt' tidak ditemukan setelah cleansing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVMy3fKs2AO0",
        "outputId": "f758faef-4ed8-4e12-9fa2-795007bbd43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================= Cleansing Kolom Koordinat =========================\n",
            "\n",
            "‚ÑπÔ∏è Memproses kolom 'koordinat_olt' (gabungan Latitude, Longitude)...\n",
            "‚úÖ apply_cleaning pada 'koordinat_olt' selesai.\n",
            "‚úÖ Split 'koordinat_olt_cleaned' selesai.\n",
            "‚úÖ Kolom 0 hasil split ditugaskan ke latitude_olt.\n",
            "‚úÖ Kolom 1 hasil split ditugaskan ke longitude_olt.\n",
            "‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_olt dan longitude_olt.\n",
            "‚úÖ latitude_olt dan longitude_olt diubah ke string.\n",
            "‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\n",
            "‚úÖ clean_invalid_characters selesai pada latitude_olt dan longitude_olt.\n",
            "‚úÖ Konversi akhir ke float selesai pada latitude_olt dan longitude_olt.\n",
            "‚ÑπÔ∏è Total baris: 38968\n",
            "‚ÑπÔ∏è Baris 'koordinat_olt' non-kosong awal: 38968\n",
            "‚ÑπÔ∏è Baris 'latitude_olt' yang menjadi kosong (NaN): 191\n",
            "‚ÑπÔ∏è Baris 'longitude_olt' yang menjadi kosong (NaN): 191\n",
            "‚úÖ Kolom 'koordinat_olt_cleaned' dihapus.\n",
            "\n",
            "üìã Info aset_data setelah cleansing koordinat:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   pa                      38968 non-null  string        \n",
            " 1   tanggal_rfs             21061 non-null  datetime64[ns]\n",
            " 2   mitra                   38968 non-null  string        \n",
            " 3   kategori                38968 non-null  string        \n",
            " 4   area_kp                 38968 non-null  string        \n",
            " 5   kota_kab                38968 non-null  string        \n",
            " 6   lokasi_olt              38968 non-null  object        \n",
            " 7   hostname_olt            38968 non-null  string        \n",
            " 8   brand_olt               38968 non-null  string        \n",
            " 9   type_olt                38968 non-null  string        \n",
            " 10  kapasitas_olt           34421 non-null  Int64         \n",
            " 11  kapasitas_port_olt      24613 non-null  Int64         \n",
            " 12  olt_port                30735 non-null  Int64         \n",
            " 13  interface_olt           38968 non-null  string        \n",
            " 14  fdt_new_existing        38968 non-null  string        \n",
            " 15  fdt_id                  38968 non-null  string        \n",
            " 16  jumlah_splitter_fdt     27222 non-null  Int64         \n",
            " 17  kapasitas_splitter_fdt  33031 non-null  Int64         \n",
            " 18  koordinat_fdt           38968 non-null  string        \n",
            " 19  port_fdt                22794 non-null  Int64         \n",
            " 20  status_osp_amarta_fdt   38968 non-null  string        \n",
            " 21  cluster                 38968 non-null  string        \n",
            " 22  koordinat_cluster       38968 non-null  string        \n",
            " 23  fat_id                  38968 non-null  string        \n",
            " 24  jumlah_splitter_fat     30188 non-null  Int64         \n",
            " 25  kapasitas_splitter_fat  38820 non-null  Int64         \n",
            " 26  koordinat_fat           38968 non-null  string        \n",
            " 27  status_osp_amarta_fat   38968 non-null  string        \n",
            " 28  kecamatan               38968 non-null  string        \n",
            " 29  kelurahan               38968 non-null  string        \n",
            " 30  sumber_datek            38968 non-null  string        \n",
            " 31  hc_old                  27471 non-null  Int64         \n",
            " 32  hc_icrm                 25602 non-null  Int64         \n",
            " 33  total_hc                38941 non-null  Int64         \n",
            " 34  cleansing_hp            38968 non-null  string        \n",
            " 35  olt                     38968 non-null  string        \n",
            " 36  update_aset             38968 non-null  string        \n",
            " 37  fat_kondisi             38968 non-null  string        \n",
            " 38  filter_fat_cap          38968 non-null  string        \n",
            " 39  fat_id_x                38968 non-null  string        \n",
            " 40  fat_filter_pemakaian    38968 non-null  string        \n",
            " 41  keterangan_full         38968 non-null  string        \n",
            " 42  amarta_update           38968 non-null  string        \n",
            " 43  link_dokumen_feeder     38968 non-null  string        \n",
            " 44  keterangan_dokumen      38968 non-null  string        \n",
            " 45  link_data_aset          38968 non-null  string        \n",
            " 46  keterangan_data_aset    38968 non-null  string        \n",
            " 47  link_maps               38968 non-null  string        \n",
            " 48  up3                     38968 non-null  string        \n",
            " 49  ulp                     38968 non-null  string        \n",
            " 50  latitude_olt            38777 non-null  float64       \n",
            " 51  longitude_olt           38777 non-null  float64       \n",
            "dtypes: Int64(11), datetime64[ns](1), float64(2), object(1), string(37)\n",
            "memory usage: 16.2+ MB\n",
            "\n",
            "üìã Info kolom 'latitude_olt' dan 'longitude_olt' setelah cleansing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   latitude_olt   38777 non-null  float64\n",
            " 1   longitude_olt  38777 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 913.3 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aset_data.to_csv(\"data_clean/aset_data_clean.csv\", index=False)"
      ],
      "metadata": {
        "id": "HHkznMHScIXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_latitude(value):\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "    value = str(value).replace(\" \", \"\").replace(\",\", \".\")\n",
        "    match = re.match(r\"(-?\\d+)\\.(\\d+)\", value)\n",
        "    if not match:\n",
        "        return np.nan\n",
        "    pre, post = match.groups()\n",
        "\n",
        "    if len(pre.replace(\"-\", \"\")) > 2:\n",
        "        # contoh: -727.037 ‚Üí -7.27037\n",
        "        new_pre = pre[:-2]  # ambil dua angka terakhir jadi bagian depan desimal\n",
        "        new_post = pre[-2:] + post\n",
        "        return float(f\"{new_pre}.{new_post}\")\n",
        "    return float(value)\n",
        "\n",
        "def fix_longitude(value):\n",
        "    if pd.isna(value):\n",
        "        return np.nan\n",
        "    value = str(value).replace(\" \", \"\").replace(\",\", \".\")\n",
        "    match = re.match(r\"(-?\\d+)\\.(\\d+)\", value)\n",
        "    if not match:\n",
        "        return np.nan\n",
        "    pre, post = match.groups()\n",
        "\n",
        "    if len(pre) > 3:\n",
        "        # contoh: 11233.925 ‚Üí 112.33925\n",
        "        new_pre = pre[:-3]\n",
        "        new_post = pre[-3:] + post\n",
        "        return float(f\"{new_pre}.{new_post}\")\n",
        "    return float(value)"
      ],
      "metadata": {
        "id": "yw58w_yXtNtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========================= Cleansing Kolom Koordinat =========================\\n\")\n",
        "\n",
        "# Asumsi kolom 'koordinat_fdt' ada\n",
        "if 'koordinat_fdt' in aset_data.columns:\n",
        "    print(\"‚ÑπÔ∏è Memproses kolom 'koordinat_fdt' (gabungan Latitude, Longitude)...\")\n",
        "    try:\n",
        "        # Langkah 1: Pembersihan awal pada string koordinat\n",
        "        aset_data[\"koordinat_fdt_cleaned\"] = aset_data[\"koordinat_fdt\"].apply(apply_cleaning)\n",
        "        print(\"‚úÖ apply_cleaning pada 'koordinat_fdt' selesai.\")\n",
        "\n",
        "        # Langkah 2: Pisahkan string koordinat menjadi Latitude dan Longitude\n",
        "        split_coords = aset_data[\"koordinat_fdt_cleaned\"].str.split(',', expand=True)\n",
        "        print(\"‚úÖ Split 'koordinat_fdt_cleaned' selesai.\")\n",
        "\n",
        "        # Langkah 3: Inisialisasi kolom latitude_fdt dan longitude_fdt dengan NaN\n",
        "        aset_data[\"latitude_fdt\"] = np.nan\n",
        "        aset_data[\"longitude_fdt\"] = np.nan\n",
        "\n",
        "        # Tugaskan hasil split ke kolom target\n",
        "        if split_coords.shape[1] > 0:\n",
        "            aset_data[\"latitude_fdt\"] = split_coords[0]\n",
        "            print(\"‚úÖ Kolom 0 hasil split ditugaskan ke latitude_fdt.\")\n",
        "\n",
        "        if split_coords.shape[1] > 1:\n",
        "            aset_data[\"longitude_fdt\"] = split_coords[1]\n",
        "            print(\"‚úÖ Kolom 1 hasil split ditugaskan ke longitude_fdt.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Split tidak menghasilkan 2 kolom, longitude_fdt mungkin diisi NaN atau tidak berubah.\")\n",
        "\n",
        "        # Langkah 4: Pembersihan dan konversi akhir\n",
        "        print(\"‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_fdt dan longitude_fdt.\")\n",
        "        aset_data[\"latitude_fdt\"] = aset_data[\"latitude_fdt\"].astype(str)\n",
        "        aset_data[\"longitude_fdt\"] = aset_data[\"longitude_fdt\"].astype(str)\n",
        "        print(\"‚úÖ latitude_fdt dan longitude_fdt diubah ke string.\")\n",
        "\n",
        "        aset_data[\"latitude_fdt\"] = aset_data[\"latitude_fdt\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        aset_data[\"longitude_fdt\"] = aset_data[\"longitude_fdt\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        print(\"‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\")\n",
        "\n",
        "        aset_data[\"latitude_fdt\"] = aset_data[\"latitude_fdt\"].apply(clean_invalid_characters)\n",
        "        aset_data[\"longitude_fdt\"] = aset_data[\"longitude_fdt\"].apply(clean_invalid_characters)\n",
        "        print(\"‚úÖ clean_invalid_characters selesai pada latitude_fdt dan longitude_fdt.\")\n",
        "\n",
        "        aset_data[\"latitude_fdt\"] = pd.to_numeric(aset_data[\"latitude_fdt\"], errors=\"coerce\")\n",
        "        aset_data[\"longitude_fdt\"] = pd.to_numeric(aset_data[\"longitude_fdt\"], errors=\"coerce\")\n",
        "        print(\"‚úÖ Konversi akhir ke float selesai pada latitude_fdt dan longitude_fdt.\")\n",
        "\n",
        "        # Hitung jumlah baris non-null awal dan setelah proses\n",
        "        initial_coord_non_null = aset_data[\"koordinat_fdt\"].notna().sum()\n",
        "        final_lat_null_count = aset_data[\"latitude_fdt\"].isna().sum()\n",
        "        final_lon_null_count = aset_data[\"longitude_fdt\"].isna().sum()\n",
        "        print(f\"‚ÑπÔ∏è Total baris: {len(aset_data)}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'koordinat_fdt' non-kosong awal: {initial_coord_non_null}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'latitude_fdt' yang menjadi kosong (NaN): {final_lat_null_count}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'longitude_fdt' yang menjadi kosong (NaN): {final_lon_null_count}\")\n",
        "\n",
        "        # Drop kolom sementara jika tidak lagi dibutuhkan\n",
        "        if \"koordinat_fdt_cleaned\" in aset_data.columns:\n",
        "            aset_data.drop(columns=[\"koordinat_fdt_cleaned\", \"koordinat_fdt\"], inplace=True)\n",
        "            print(\"‚úÖ Kolom 'koordinat_fdt_cleaned' dihapus.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error dalam proses cleansing koordinat FDT: {e}\")\n",
        "        if \"latitude_fdt\" not in aset_data.columns:\n",
        "            aset_data[\"latitude_fdt\"] = np.nan\n",
        "        if \"longitude_fdt\" not in aset_data.columns:\n",
        "            aset_data[\"longitude_fdt\"] = np.nan\n",
        "        print(\"‚ö†Ô∏è Kolom latitude_fdt dan longitude_fdt mungkin tidak terproses sepenuhnya karena error.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kolom 'koordinat_fdt' tidak ditemukan dalam aset_data. Melewatkan cleansing koordinat FDT.\")\n",
        "\n",
        "# Output informasi\n",
        "print(\"\\nüìã Info aset_data setelah cleansing koordinat:\")\n",
        "aset_data.info()\n",
        "\n",
        "if \"latitude_fdt\" in aset_data.columns and \"longitude_fdt\" in aset_data.columns:\n",
        "    print(\"\\nüìã Info kolom 'latitude_fdt' dan 'longitude_fdt' setelah cleansing:\")\n",
        "    print(aset_data[[\"latitude_fdt\", \"longitude_fdt\"]].info())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Kolom 'latitude_fdt' atau 'longitude_fdt' tidak ditemukan setelah cleansing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Aqqu6T2MtY",
        "outputId": "d9b9c095-783c-4ef7-b137-3d001a097850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================= Cleansing Kolom Koordinat =========================\n",
            "\n",
            "‚ÑπÔ∏è Memproses kolom 'koordinat_fdt' (gabungan Latitude, Longitude)...\n",
            "‚úÖ apply_cleaning pada 'koordinat_fdt' selesai.\n",
            "‚úÖ Split 'koordinat_fdt_cleaned' selesai.\n",
            "‚úÖ Kolom 0 hasil split ditugaskan ke latitude_fdt.\n",
            "‚úÖ Kolom 1 hasil split ditugaskan ke longitude_fdt.\n",
            "‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_fdt dan longitude_fdt.\n",
            "‚úÖ latitude_fdt dan longitude_fdt diubah ke string.\n",
            "‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\n",
            "‚úÖ clean_invalid_characters selesai pada latitude_fdt dan longitude_fdt.\n",
            "‚úÖ Konversi akhir ke float selesai pada latitude_fdt dan longitude_fdt.\n",
            "‚ÑπÔ∏è Total baris: 38968\n",
            "‚ÑπÔ∏è Baris 'koordinat_fdt' non-kosong awal: 38968\n",
            "‚ÑπÔ∏è Baris 'latitude_fdt' yang menjadi kosong (NaN): 227\n",
            "‚ÑπÔ∏è Baris 'longitude_fdt' yang menjadi kosong (NaN): 227\n",
            "‚úÖ Kolom 'koordinat_fdt_cleaned' dihapus.\n",
            "\n",
            "üìã Info aset_data setelah cleansing koordinat:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 53 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   pa                      38968 non-null  string        \n",
            " 1   tanggal_rfs             21061 non-null  datetime64[ns]\n",
            " 2   mitra                   38968 non-null  string        \n",
            " 3   kategori                38968 non-null  string        \n",
            " 4   area_kp                 38968 non-null  string        \n",
            " 5   kota_kab                38968 non-null  string        \n",
            " 6   lokasi_olt              38968 non-null  object        \n",
            " 7   hostname_olt            38968 non-null  string        \n",
            " 8   brand_olt               38968 non-null  string        \n",
            " 9   type_olt                38968 non-null  string        \n",
            " 10  kapasitas_olt           34421 non-null  Int64         \n",
            " 11  kapasitas_port_olt      24613 non-null  Int64         \n",
            " 12  olt_port                30735 non-null  Int64         \n",
            " 13  interface_olt           38968 non-null  string        \n",
            " 14  fdt_new_existing        38968 non-null  string        \n",
            " 15  fdt_id                  38968 non-null  string        \n",
            " 16  jumlah_splitter_fdt     27222 non-null  Int64         \n",
            " 17  kapasitas_splitter_fdt  33031 non-null  Int64         \n",
            " 18  port_fdt                22794 non-null  Int64         \n",
            " 19  status_osp_amarta_fdt   38968 non-null  string        \n",
            " 20  cluster                 38968 non-null  string        \n",
            " 21  koordinat_cluster       38968 non-null  string        \n",
            " 22  fat_id                  38968 non-null  string        \n",
            " 23  jumlah_splitter_fat     30188 non-null  Int64         \n",
            " 24  kapasitas_splitter_fat  38820 non-null  Int64         \n",
            " 25  koordinat_fat           38968 non-null  string        \n",
            " 26  status_osp_amarta_fat   38968 non-null  string        \n",
            " 27  kecamatan               38968 non-null  string        \n",
            " 28  kelurahan               38968 non-null  string        \n",
            " 29  sumber_datek            38968 non-null  string        \n",
            " 30  hc_old                  27471 non-null  Int64         \n",
            " 31  hc_icrm                 25602 non-null  Int64         \n",
            " 32  total_hc                38941 non-null  Int64         \n",
            " 33  cleansing_hp            38968 non-null  string        \n",
            " 34  olt                     38968 non-null  string        \n",
            " 35  update_aset             38968 non-null  string        \n",
            " 36  fat_kondisi             38968 non-null  string        \n",
            " 37  filter_fat_cap          38968 non-null  string        \n",
            " 38  fat_id_x                38968 non-null  string        \n",
            " 39  fat_filter_pemakaian    38968 non-null  string        \n",
            " 40  keterangan_full         38968 non-null  string        \n",
            " 41  amarta_update           38968 non-null  string        \n",
            " 42  link_dokumen_feeder     38968 non-null  string        \n",
            " 43  keterangan_dokumen      38968 non-null  string        \n",
            " 44  link_data_aset          38968 non-null  string        \n",
            " 45  keterangan_data_aset    38968 non-null  string        \n",
            " 46  link_maps               38968 non-null  string        \n",
            " 47  up3                     38968 non-null  string        \n",
            " 48  ulp                     38968 non-null  string        \n",
            " 49  latitude_olt            38777 non-null  float64       \n",
            " 50  longitude_olt           38777 non-null  float64       \n",
            " 51  latitude_fdt            38741 non-null  float64       \n",
            " 52  longitude_fdt           38741 non-null  float64       \n",
            "dtypes: Int64(11), datetime64[ns](1), float64(4), object(1), string(36)\n",
            "memory usage: 16.5+ MB\n",
            "\n",
            "üìã Info kolom 'latitude_fdt' dan 'longitude_fdt' setelah cleansing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   latitude_fdt   38741 non-null  float64\n",
            " 1   longitude_fdt  38741 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 913.3 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========================= Cleansing Kolom Koordinat =========================\\n\")\n",
        "\n",
        "# Asumsi kolom 'koordinat_fat' ada\n",
        "if 'koordinat_fat' in aset_data.columns:\n",
        "    print(\"‚ÑπÔ∏è Memproses kolom 'koordinat_fat' (gabungan Latitude, Longitude)...\")\n",
        "    try:\n",
        "        # Langkah 1: Pembersihan awal pada string koordinat\n",
        "        aset_data[\"koordinat_fat_cleaned\"] = aset_data[\"koordinat_fat\"].apply(apply_cleaning)\n",
        "        print(\"‚úÖ apply_cleaning pada 'koordinat_fat' selesai.\")\n",
        "\n",
        "        # Langkah 2: Pisahkan string koordinat menjadi Latitude dan Longitude\n",
        "        split_coords = aset_data[\"koordinat_fat_cleaned\"].str.split(',', expand=True)\n",
        "        print(\"‚úÖ Split 'koordinat_fat_cleaned' selesai.\")\n",
        "\n",
        "        # Langkah 3: Inisialisasi kolom latitude_fat dan longitude_fat dengan NaN\n",
        "        aset_data[\"latitude_fat\"] = np.nan\n",
        "        aset_data[\"longitude_fat\"] = np.nan\n",
        "\n",
        "        # Tugaskan hasil split ke kolom target\n",
        "        if split_coords.shape[1] > 0:\n",
        "            aset_data[\"latitude_fat\"] = split_coords[0]\n",
        "            print(\"‚úÖ Kolom 0 hasil split ditugaskan ke latitude_fat.\")\n",
        "\n",
        "        if split_coords.shape[1] > 1:\n",
        "            aset_data[\"longitude_fat\"] = split_coords[1]\n",
        "            print(\"‚úÖ Kolom 1 hasil split ditugaskan ke longitude_fat.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Split tidak menghasilkan 2 kolom, longitude_fat mungkin diisi NaN atau tidak berubah.\")\n",
        "\n",
        "        # Langkah 4: Pembersihan dan konversi akhir\n",
        "        print(\"‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_fat dan longitude_fat.\")\n",
        "        aset_data[\"latitude_fat\"] = aset_data[\"latitude_fat\"].astype(str)\n",
        "        aset_data[\"longitude_fat\"] = aset_data[\"longitude_fat\"].astype(str)\n",
        "        print(\"‚úÖ latitude_fat dan longitude_fat diubah ke string.\")\n",
        "\n",
        "        aset_data[\"latitude_fat\"] = aset_data[\"latitude_fat\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        aset_data[\"longitude_fat\"] = aset_data[\"longitude_fat\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        print(\"‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\")\n",
        "\n",
        "        aset_data[\"latitude_fat\"] = aset_data[\"latitude_fat\"].apply(clean_invalid_characters)\n",
        "        aset_data[\"longitude_fat\"] = aset_data[\"longitude_fat\"].apply(clean_invalid_characters)\n",
        "        print(\"‚úÖ clean_invalid_characters selesai pada latitude_fat dan longitude_fat.\")\n",
        "\n",
        "        aset_data[\"latitude_fat\"] = pd.to_numeric(aset_data[\"latitude_fat\"], errors=\"coerce\")\n",
        "        aset_data[\"longitude_fat\"] = pd.to_numeric(aset_data[\"longitude_fat\"], errors=\"coerce\")\n",
        "        print(\"‚úÖ Konversi akhir ke float selesai pada latitude_fat dan longitude_fat.\")\n",
        "\n",
        "        # Hitung jumlah baris non-null awal dan setelah proses\n",
        "        initial_coord_non_null = aset_data[\"koordinat_fat\"].notna().sum()\n",
        "        final_lat_null_count = aset_data[\"latitude_fat\"].isna().sum()\n",
        "        final_lon_null_count = aset_data[\"longitude_fat\"].isna().sum()\n",
        "        print(f\"‚ÑπÔ∏è Total baris: {len(aset_data)}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'koordinat_fat' non-kosong awal: {initial_coord_non_null}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'latitude_fat' yang menjadi kosong (NaN): {final_lat_null_count}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'longitude_fat' yang menjadi kosong (NaN): {final_lon_null_count}\")\n",
        "\n",
        "        # Drop kolom sementara jika tidak lagi dibutuhkan\n",
        "        if \"koordinat_fat_cleaned\" in aset_data.columns:\n",
        "            aset_data.drop(columns=[\"koordinat_fat_cleaned\", \"koordinat_fat\"], inplace=True)\n",
        "            print(\"‚úÖ Kolom 'koordinat_fat_cleaned' dihapus.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error dalam proses cleansing koordinat FAT: {e}\")\n",
        "        if \"latitude_fat\" not in aset_data.columns:\n",
        "            aset_data[\"latitude_fat\"] = np.nan\n",
        "        if \"longitude_fat\" not in aset_data.columns:\n",
        "            aset_data[\"longitude_fat\"] = np.nan\n",
        "        print(\"‚ö†Ô∏è Kolom latitude_fat dan longitude_fat mungkin tidak terproses sepenuhnya karena error.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kolom 'koordinat_fat' tidak ditemukan dalam aset_data. Melewatkan cleansing koordinat FAT.\")\n",
        "\n",
        "# Output informasi\n",
        "print(\"\\nüìã Info aset_data setelah cleansing koordinat:\")\n",
        "aset_data.info()\n",
        "\n",
        "if \"latitude_fat\" in aset_data.columns and \"longitude_fat\" in aset_data.columns:\n",
        "    print(\"\\nüìã Info kolom 'latitude_fat' dan 'longitude_fat' setelah cleansing:\")\n",
        "    print(aset_data[[\"latitude_fat\", \"longitude_fat\"]].info())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Kolom 'latitude_fat' atau 'longitude_fat' tidak ditemukan setelah cleansing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF-bAiGCCDKe",
        "outputId": "ed8bde7d-038f-45c2-a97f-9d3e85a67a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================= Cleansing Kolom Koordinat =========================\n",
            "\n",
            "‚ÑπÔ∏è Memproses kolom 'koordinat_fat' (gabungan Latitude, Longitude)...\n",
            "‚úÖ apply_cleaning pada 'koordinat_fat' selesai.\n",
            "‚úÖ Split 'koordinat_fat_cleaned' selesai.\n",
            "‚úÖ Kolom 0 hasil split ditugaskan ke latitude_fat.\n",
            "‚úÖ Kolom 1 hasil split ditugaskan ke longitude_fat.\n",
            "‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_fat dan longitude_fat.\n",
            "‚úÖ latitude_fat dan longitude_fat diubah ke string.\n",
            "‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\n",
            "‚úÖ clean_invalid_characters selesai pada latitude_fat dan longitude_fat.\n",
            "‚úÖ Konversi akhir ke float selesai pada latitude_fat dan longitude_fat.\n",
            "‚ÑπÔ∏è Total baris: 38968\n",
            "‚ÑπÔ∏è Baris 'koordinat_fat' non-kosong awal: 38968\n",
            "‚ÑπÔ∏è Baris 'latitude_fat' yang menjadi kosong (NaN): 36\n",
            "‚ÑπÔ∏è Baris 'longitude_fat' yang menjadi kosong (NaN): 36\n",
            "‚úÖ Kolom 'koordinat_fat_cleaned' dihapus.\n",
            "\n",
            "üìã Info aset_data setelah cleansing koordinat:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 54 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   pa                      38968 non-null  string        \n",
            " 1   tanggal_rfs             21061 non-null  datetime64[ns]\n",
            " 2   mitra                   38968 non-null  string        \n",
            " 3   kategori                38968 non-null  string        \n",
            " 4   area_kp                 38968 non-null  string        \n",
            " 5   kota_kab                38968 non-null  string        \n",
            " 6   lokasi_olt              38968 non-null  object        \n",
            " 7   hostname_olt            38968 non-null  string        \n",
            " 8   brand_olt               38968 non-null  string        \n",
            " 9   type_olt                38968 non-null  string        \n",
            " 10  kapasitas_olt           34421 non-null  Int64         \n",
            " 11  kapasitas_port_olt      24613 non-null  Int64         \n",
            " 12  olt_port                30735 non-null  Int64         \n",
            " 13  interface_olt           38968 non-null  string        \n",
            " 14  fdt_new_existing        38968 non-null  string        \n",
            " 15  fdt_id                  38968 non-null  string        \n",
            " 16  jumlah_splitter_fdt     27222 non-null  Int64         \n",
            " 17  kapasitas_splitter_fdt  33031 non-null  Int64         \n",
            " 18  port_fdt                22794 non-null  Int64         \n",
            " 19  status_osp_amarta_fdt   38968 non-null  string        \n",
            " 20  cluster                 38968 non-null  string        \n",
            " 21  koordinat_cluster       38968 non-null  string        \n",
            " 22  fat_id                  38968 non-null  string        \n",
            " 23  jumlah_splitter_fat     30188 non-null  Int64         \n",
            " 24  kapasitas_splitter_fat  38820 non-null  Int64         \n",
            " 25  status_osp_amarta_fat   38968 non-null  string        \n",
            " 26  kecamatan               38968 non-null  string        \n",
            " 27  kelurahan               38968 non-null  string        \n",
            " 28  sumber_datek            38968 non-null  string        \n",
            " 29  hc_old                  27471 non-null  Int64         \n",
            " 30  hc_icrm                 25602 non-null  Int64         \n",
            " 31  total_hc                38941 non-null  Int64         \n",
            " 32  cleansing_hp            38968 non-null  string        \n",
            " 33  olt                     38968 non-null  string        \n",
            " 34  update_aset             38968 non-null  string        \n",
            " 35  fat_kondisi             38968 non-null  string        \n",
            " 36  filter_fat_cap          38968 non-null  string        \n",
            " 37  fat_id_x                38968 non-null  string        \n",
            " 38  fat_filter_pemakaian    38968 non-null  string        \n",
            " 39  keterangan_full         38968 non-null  string        \n",
            " 40  amarta_update           38968 non-null  string        \n",
            " 41  link_dokumen_feeder     38968 non-null  string        \n",
            " 42  keterangan_dokumen      38968 non-null  string        \n",
            " 43  link_data_aset          38968 non-null  string        \n",
            " 44  keterangan_data_aset    38968 non-null  string        \n",
            " 45  link_maps               38968 non-null  string        \n",
            " 46  up3                     38968 non-null  string        \n",
            " 47  ulp                     38968 non-null  string        \n",
            " 48  latitude_olt            38777 non-null  float64       \n",
            " 49  longitude_olt           38777 non-null  float64       \n",
            " 50  latitude_fdt            38741 non-null  float64       \n",
            " 51  longitude_fdt           38741 non-null  float64       \n",
            " 52  latitude_fat            38932 non-null  float64       \n",
            " 53  longitude_fat           38932 non-null  float64       \n",
            "dtypes: Int64(11), datetime64[ns](1), float64(6), object(1), string(35)\n",
            "memory usage: 16.8+ MB\n",
            "\n",
            "üìã Info kolom 'latitude_fat' dan 'longitude_fat' setelah cleansing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   latitude_fat   38932 non-null  float64\n",
            " 1   longitude_fat  38932 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 913.3 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========================= Cleansing Kolom Koordinat =========================\\n\")\n",
        "\n",
        "# Asumsi kolom 'koordinat_cluster' ada\n",
        "if 'koordinat_cluster' in aset_data.columns:\n",
        "    print(\"‚ÑπÔ∏è Memproses kolom 'koordinat_cluster' (gabungan Latitude, Longitude)...\")\n",
        "    try:\n",
        "        # Langkah 1: Pembersihan awal pada string koordinat\n",
        "        aset_data[\"koordinat_cluster_cleaned\"] = aset_data[\"koordinat_cluster\"].apply(apply_cleaning)\n",
        "        print(\"‚úÖ apply_cleaning pada 'koordinat_cluster' selesai.\")\n",
        "\n",
        "        # Langkah 2: Pisahkan string koordinat menjadi Latitude dan Longitude\n",
        "        split_coords = aset_data[\"koordinat_cluster_cleaned\"].str.split(',', expand=True)\n",
        "        print(\"‚úÖ Split 'koordinat_cluster_cleaned' selesai.\")\n",
        "\n",
        "        # Langkah 3: Inisialisasi kolom latitude_cluster dan longitude_cluster dengan NaN\n",
        "        aset_data[\"latitude_cluster\"] = np.nan\n",
        "        aset_data[\"longitude_cluster\"] = np.nan\n",
        "\n",
        "        # Tugaskan hasil split ke kolom target\n",
        "        if split_coords.shape[1] > 0:\n",
        "            aset_data[\"latitude_cluster\"] = split_coords[0]\n",
        "            print(\"‚úÖ Kolom 0 hasil split ditugaskan ke latitude_cluster.\")\n",
        "\n",
        "        if split_coords.shape[1] > 1:\n",
        "            aset_data[\"longitude_cluster\"] = split_coords[1]\n",
        "            print(\"‚úÖ Kolom 1 hasil split ditugaskan ke longitude_cluster.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Split tidak menghasilkan 2 kolom, longitude_cluster mungkin diisi NaN atau tidak berubah.\")\n",
        "\n",
        "        # Langkah 4: Pembersihan dan konversi akhir\n",
        "        print(\"‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_cluster dan longitude_cluster.\")\n",
        "        aset_data[\"latitude_cluster\"] = aset_data[\"latitude_cluster\"].astype(str)\n",
        "        aset_data[\"longitude_cluster\"] = aset_data[\"longitude_cluster\"].astype(str)\n",
        "        print(\"‚úÖ latitude_cluster dan longitude_cluster diubah ke string.\")\n",
        "\n",
        "        aset_data[\"latitude_cluster\"] = aset_data[\"latitude_cluster\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        aset_data[\"longitude_cluster\"] = aset_data[\"longitude_cluster\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        print(\"‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\")\n",
        "\n",
        "        aset_data[\"latitude_cluster\"] = aset_data[\"latitude_cluster\"].apply(clean_invalid_characters)\n",
        "        aset_data[\"longitude_cluster\"] = aset_data[\"longitude_cluster\"].apply(clean_invalid_characters)\n",
        "        print(\"‚úÖ clean_invalid_characters selesai pada latitude_cluster dan longitude_cluster.\")\n",
        "\n",
        "        aset_data[\"latitude_cluster\"] = pd.to_numeric(aset_data[\"latitude_cluster\"], errors=\"coerce\")\n",
        "        aset_data[\"longitude_cluster\"] = pd.to_numeric(aset_data[\"longitude_cluster\"], errors=\"coerce\")\n",
        "        print(\"‚úÖ Konversi akhir ke float selesai pada latitude_cluster dan longitude_cluster.\")\n",
        "\n",
        "        # Hitung jumlah baris non-null awal dan setelah proses\n",
        "        initial_coord_non_null = aset_data[\"koordinat_cluster\"].notna().sum()\n",
        "        final_lat_null_count = aset_data[\"latitude_cluster\"].isna().sum()\n",
        "        final_lon_null_count = aset_data[\"longitude_cluster\"].isna().sum()\n",
        "        print(f\"‚ÑπÔ∏è Total baris: {len(aset_data)}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'koordinat_cluster' non-kosong awal: {initial_coord_non_null}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'latitude_cluster' yang menjadi kosong (NaN): {final_lat_null_count}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'longitude_cluster' yang menjadi kosong (NaN): {final_lon_null_count}\")\n",
        "\n",
        "        # Drop kolom sementara jika tidak lagi dibutuhkan\n",
        "        if \"koordinat_cluster_cleaned\" in aset_data.columns:\n",
        "            aset_data.drop(columns=[\"koordinat_cluster_cleaned\", \"koordinat_cluster\"], inplace=True)\n",
        "            print(\"‚úÖ Kolom 'koordinat_cluster_cleaned' dihapus.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error dalam proses cleansing koordinat CLUSTER: {e}\")\n",
        "        if \"latitude_cluster\" not in aset_data.columns:\n",
        "            aset_data[\"latitude_cluster\"] = np.nan\n",
        "        if \"longitude_cluster\" not in aset_data.columns:\n",
        "            aset_data[\"longitude_cluster\"] = np.nan\n",
        "        print(\"‚ö†Ô∏è Kolom latitude_cluster dan longitude_cluster mungkin tidak terproses sepenuhnya karena error.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kolom 'koordinat_cluster' tidak ditemukan dalam aset_data. Melewatkan cleansing koordinat CLUSTER.\")\n",
        "\n",
        "# Output informasi\n",
        "print(\"\\nüìã Info aset_data setelah cleansing koordinat:\")\n",
        "aset_data.info()\n",
        "\n",
        "if \"latitude_cluster\" in aset_data.columns and \"longitude_cluster\" in aset_data.columns:\n",
        "    print(\"\\nüìã Info kolom 'latitude_cluster' dan 'longitude_cluster' setelah cleansing:\")\n",
        "    print(aset_data[[\"latitude_cluster\", \"longitude_cluster\"]].info())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Kolom 'latitude_cluster' atau 'longitude_cluster' tidak ditemukan setelah cleansing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OTNFd0LJ7RQ",
        "outputId": "9ab05d19-6d40-40ae-e7cf-6478887e7cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================= Cleansing Kolom Koordinat =========================\n",
            "\n",
            "‚ÑπÔ∏è Memproses kolom 'koordinat_cluster' (gabungan Latitude, Longitude)...\n",
            "‚úÖ apply_cleaning pada 'koordinat_cluster' selesai.\n",
            "‚úÖ Split 'koordinat_cluster_cleaned' selesai.\n",
            "‚úÖ Kolom 0 hasil split ditugaskan ke latitude_cluster.\n",
            "‚úÖ Kolom 1 hasil split ditugaskan ke longitude_cluster.\n",
            "‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_cluster dan longitude_cluster.\n",
            "‚úÖ latitude_cluster dan longitude_cluster diubah ke string.\n",
            "‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\n",
            "‚úÖ clean_invalid_characters selesai pada latitude_cluster dan longitude_cluster.\n",
            "‚úÖ Konversi akhir ke float selesai pada latitude_cluster dan longitude_cluster.\n",
            "‚ÑπÔ∏è Total baris: 38968\n",
            "‚ÑπÔ∏è Baris 'koordinat_cluster' non-kosong awal: 38968\n",
            "‚ÑπÔ∏è Baris 'latitude_cluster' yang menjadi kosong (NaN): 18696\n",
            "‚ÑπÔ∏è Baris 'longitude_cluster' yang menjadi kosong (NaN): 18696\n",
            "‚úÖ Kolom 'koordinat_cluster_cleaned' dihapus.\n",
            "\n",
            "üìã Info aset_data setelah cleansing koordinat:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 55 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   pa                      38968 non-null  string        \n",
            " 1   tanggal_rfs             21061 non-null  datetime64[ns]\n",
            " 2   mitra                   38968 non-null  string        \n",
            " 3   kategori                38968 non-null  string        \n",
            " 4   area_kp                 38968 non-null  string        \n",
            " 5   kota_kab                38968 non-null  string        \n",
            " 6   lokasi_olt              38968 non-null  object        \n",
            " 7   hostname_olt            38968 non-null  string        \n",
            " 8   brand_olt               38968 non-null  string        \n",
            " 9   type_olt                38968 non-null  string        \n",
            " 10  kapasitas_olt           34421 non-null  Int64         \n",
            " 11  kapasitas_port_olt      24613 non-null  Int64         \n",
            " 12  olt_port                30735 non-null  Int64         \n",
            " 13  interface_olt           38968 non-null  string        \n",
            " 14  fdt_new_existing        38968 non-null  string        \n",
            " 15  fdt_id                  38968 non-null  string        \n",
            " 16  jumlah_splitter_fdt     27222 non-null  Int64         \n",
            " 17  kapasitas_splitter_fdt  33031 non-null  Int64         \n",
            " 18  port_fdt                22794 non-null  Int64         \n",
            " 19  status_osp_amarta_fdt   38968 non-null  string        \n",
            " 20  cluster                 38968 non-null  string        \n",
            " 21  fat_id                  38968 non-null  string        \n",
            " 22  jumlah_splitter_fat     30188 non-null  Int64         \n",
            " 23  kapasitas_splitter_fat  38820 non-null  Int64         \n",
            " 24  status_osp_amarta_fat   38968 non-null  string        \n",
            " 25  kecamatan               38968 non-null  string        \n",
            " 26  kelurahan               38968 non-null  string        \n",
            " 27  sumber_datek            38968 non-null  string        \n",
            " 28  hc_old                  27471 non-null  Int64         \n",
            " 29  hc_icrm                 25602 non-null  Int64         \n",
            " 30  total_hc                38941 non-null  Int64         \n",
            " 31  cleansing_hp            38968 non-null  string        \n",
            " 32  olt                     38968 non-null  string        \n",
            " 33  update_aset             38968 non-null  string        \n",
            " 34  fat_kondisi             38968 non-null  string        \n",
            " 35  filter_fat_cap          38968 non-null  string        \n",
            " 36  fat_id_x                38968 non-null  string        \n",
            " 37  fat_filter_pemakaian    38968 non-null  string        \n",
            " 38  keterangan_full         38968 non-null  string        \n",
            " 39  amarta_update           38968 non-null  string        \n",
            " 40  link_dokumen_feeder     38968 non-null  string        \n",
            " 41  keterangan_dokumen      38968 non-null  string        \n",
            " 42  link_data_aset          38968 non-null  string        \n",
            " 43  keterangan_data_aset    38968 non-null  string        \n",
            " 44  link_maps               38968 non-null  string        \n",
            " 45  up3                     38968 non-null  string        \n",
            " 46  ulp                     38968 non-null  string        \n",
            " 47  latitude_olt            38777 non-null  float64       \n",
            " 48  longitude_olt           38777 non-null  float64       \n",
            " 49  latitude_fdt            38741 non-null  float64       \n",
            " 50  longitude_fdt           38741 non-null  float64       \n",
            " 51  latitude_fat            38932 non-null  float64       \n",
            " 52  longitude_fat           38932 non-null  float64       \n",
            " 53  latitude_cluster        20272 non-null  float64       \n",
            " 54  longitude_cluster       20272 non-null  float64       \n",
            "dtypes: Int64(11), datetime64[ns](1), float64(8), object(1), string(34)\n",
            "memory usage: 17.1+ MB\n",
            "\n",
            "üìã Info kolom 'latitude_cluster' dan 'longitude_cluster' setelah cleansing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 38968 entries, 0 to 39695\n",
            "Data columns (total 2 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   latitude_cluster   20272 non-null  float64\n",
            " 1   longitude_cluster  20272 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 913.3 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n========================= Cleansing Kolom Koordinat =========================\\n\")\n",
        "\n",
        "# Asumsi kolom 'koordinat_pelanggan' ada di user_data\n",
        "if 'koordinat_pelanggan' in user_data.columns:\n",
        "    print(\"‚ÑπÔ∏è Memproses kolom 'koordinat_pelanggan' (gabungan Latitude, Longitude) di user_data...\")\n",
        "    try:\n",
        "        # Langkah 1: Pembersihan awal pada string koordinat\n",
        "        user_data[\"koordinat_pelanggan_cleaned\"] = user_data[\"koordinat_pelanggan\"].apply(apply_cleaning)\n",
        "        print(\"‚úÖ apply_cleaning pada 'koordinat_pelanggan' selesai.\")\n",
        "\n",
        "        # Langkah 2: Pisahkan string koordinat menjadi Latitude dan Longitude\n",
        "        split_coords = user_data[\"koordinat_pelanggan_cleaned\"].str.split(',', expand=True)\n",
        "        print(\"‚úÖ Split 'koordinat_pelanggan_cleaned' selesai.\")\n",
        "\n",
        "        # Langkah 3: Inisialisasi kolom latitude_pelanggan dan longitude_pelanggan dengan NaN\n",
        "        user_data[\"latitude_pelanggan\"] = np.nan\n",
        "        user_data[\"longitude_pelanggan\"] = np.nan\n",
        "\n",
        "        # Tugaskan hasil split ke kolom target\n",
        "        if split_coords.shape[1] > 0:\n",
        "            user_data[\"latitude_pelanggan\"] = split_coords[0]\n",
        "            print(\"‚úÖ Kolom 0 hasil split ditugaskan ke latitude_pelanggan.\")\n",
        "\n",
        "        if split_coords.shape[1] > 1:\n",
        "            user_data[\"longitude_pelanggan\"] = split_coords[1]\n",
        "            print(\"‚úÖ Kolom 1 hasil split ditugaskan ke longitude_pelanggan.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Split tidak menghasilkan 2 kolom, longitude_pelanggan mungkin diisi NaN atau tidak berubah.\")\n",
        "\n",
        "        # Langkah 4: Pembersihan dan konversi akhir\n",
        "        print(\"‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_pelanggan dan longitude_pelanggan.\")\n",
        "        user_data[\"latitude_pelanggan\"] = user_data[\"latitude_pelanggan\"].astype(str)\n",
        "        user_data[\"longitude_pelanggan\"] = user_data[\"longitude_pelanggan\"].astype(str)\n",
        "        print(\"‚úÖ latitude_pelanggan dan longitude_pelanggan diubah ke string.\")\n",
        "\n",
        "        user_data[\"latitude_pelanggan\"] = user_data[\"latitude_pelanggan\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        user_data[\"longitude_pelanggan\"] = user_data[\"longitude_pelanggan\"].replace(['', '<NA>', 'None'], np.nan).str.strip()\n",
        "        print(\"‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\")\n",
        "\n",
        "        user_data[\"latitude_pelanggan\"] = user_data[\"latitude_pelanggan\"].apply(clean_invalid_characters)\n",
        "        user_data[\"longitude_pelanggan\"] = user_data[\"longitude_pelanggan\"].apply(clean_invalid_characters)\n",
        "        print(\"‚úÖ clean_invalid_characters selesai pada latitude_pelanggan dan longitude_pelanggan.\")\n",
        "\n",
        "        user_data[\"latitude_pelanggan\"] = pd.to_numeric(user_data[\"latitude_pelanggan\"], errors=\"coerce\")\n",
        "        user_data[\"longitude_pelanggan\"] = pd.to_numeric(user_data[\"longitude_pelanggan\"], errors=\"coerce\")\n",
        "        print(\"‚úÖ Konversi akhir ke float selesai pada latitude_pelanggan dan longitude_pelanggan.\")\n",
        "\n",
        "        # Hitung jumlah baris non-null awal dan setelah proses\n",
        "        initial_coord_non_null = user_data[\"koordinat_pelanggan\"].notna().sum()\n",
        "        final_lat_null_count = user_data[\"latitude_pelanggan\"].isna().sum()\n",
        "        final_lon_null_count = user_data[\"longitude_pelanggan\"].isna().sum()\n",
        "        print(f\"‚ÑπÔ∏è Total baris: {len(user_data)}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'koordinat_pelanggan' non-kosong awal: {initial_coord_non_null}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'latitude_pelanggan' yang menjadi kosong (NaN): {final_lat_null_count}\")\n",
        "        print(f\"‚ÑπÔ∏è Baris 'longitude_pelanggan' yang menjadi kosong (NaN): {final_lon_null_count}\")\n",
        "\n",
        "        # Drop kolom sementara jika tidak lagi dibutuhkan\n",
        "        if \"koordinat_pelanggan_cleaned\" in user_data.columns:\n",
        "            user_data.drop(columns=[\"koordinat_pelanggan_cleaned\", \"koordinat_pelanggan\"], inplace=True)\n",
        "            print(\"‚úÖ Kolom 'koordinat_pelanggan_cleaned' dihapus.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error dalam proses cleansing koordinat PELANGGAN: {e}\")\n",
        "        if \"latitude_pelanggan\" not in user_data.columns:\n",
        "            user_data[\"latitude_pelanggan\"] = np.nan\n",
        "        if \"longitude_pelanggan\" not in user_data.columns:\n",
        "            user_data[\"longitude_pelanggan\"] = np.nan\n",
        "        print(\"‚ö†Ô∏è Kolom latitude_pelanggan dan longitude_pelanggan mungkin tidak terproses sepenuhnya karena error.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Kolom 'koordinat_pelanggan' tidak ditemukan dalam user_data. Melewatkan cleansing koordinat PELANGGAN.\")\n",
        "\n",
        "# Output informasi\n",
        "print(\"\\nüìã Info user_data setelah cleansing koordinat:\")\n",
        "user_data.info()\n",
        "\n",
        "if \"latitude_pelanggan\" in user_data.columns and \"longitude_pelanggan\" in user_data.columns:\n",
        "    print(\"\\nüìã Info kolom 'latitude_pelanggan' dan 'longitude_pelanggan' setelah cleansing:\")\n",
        "    print(user_data[[\"latitude_pelanggan\", \"longitude_pelanggan\"]].info())\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Kolom 'latitude_pelanggan' atau 'longitude_pelanggan' tidak ditemukan setelah cleansing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKd4ovpQ1ss_",
        "outputId": "12ce466a-800b-465c-d175-45fee42e7740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================= Cleansing Kolom Koordinat =========================\n",
            "\n",
            "‚ÑπÔ∏è Memproses kolom 'koordinat_pelanggan' (gabungan Latitude, Longitude) di user_data...\n",
            "‚úÖ apply_cleaning pada 'koordinat_pelanggan' selesai.\n",
            "‚úÖ Split 'koordinat_pelanggan_cleaned' selesai.\n",
            "‚úÖ Kolom 0 hasil split ditugaskan ke latitude_pelanggan.\n",
            "‚úÖ Kolom 1 hasil split ditugaskan ke longitude_pelanggan.\n",
            "‚ÑπÔ∏è Melakukan pembersihan dan konversi akhir pada latitude_pelanggan dan longitude_pelanggan.\n",
            "‚úÖ latitude_pelanggan dan longitude_pelanggan diubah ke string.\n",
            "‚úÖ String kosong/'<NA>'/'None'/spasi di-replace dengan NaN/dihapus.\n",
            "‚úÖ clean_invalid_characters selesai pada latitude_pelanggan dan longitude_pelanggan.\n",
            "‚úÖ Konversi akhir ke float selesai pada latitude_pelanggan dan longitude_pelanggan.\n",
            "‚ÑπÔ∏è Total baris: 139016\n",
            "‚ÑπÔ∏è Baris 'koordinat_pelanggan' non-kosong awal: 139016\n",
            "‚ÑπÔ∏è Baris 'latitude_pelanggan' yang menjadi kosong (NaN): 28456\n",
            "‚ÑπÔ∏è Baris 'longitude_pelanggan' yang menjadi kosong (NaN): 28456\n",
            "‚úÖ Kolom 'koordinat_pelanggan_cleaned' dihapus.\n",
            "\n",
            "üìã Info user_data setelah cleansing koordinat:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 139016 entries, 5167 to 148442\n",
            "Data columns (total 8 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   sid                  139016 non-null  string \n",
            " 1   id_permohonan        139016 non-null  string \n",
            " 2   cust_name            139016 non-null  string \n",
            " 3   telpn                139016 non-null  string \n",
            " 4   fat_id               139016 non-null  string \n",
            " 5   notes                139016 non-null  string \n",
            " 6   latitude_pelanggan   110560 non-null  float64\n",
            " 7   longitude_pelanggan  110560 non-null  float64\n",
            "dtypes: float64(2), string(6)\n",
            "memory usage: 9.5 MB\n",
            "\n",
            "üìã Info kolom 'latitude_pelanggan' dan 'longitude_pelanggan' setelah cleansing:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 139016 entries, 5167 to 148442\n",
            "Data columns (total 2 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   latitude_pelanggan   110560 non-null  float64\n",
            " 1   longitude_pelanggan  110560 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 3.2 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================= Split Data dari aset_data =========================\n",
        "print(\"\\n=== Splitting Data from aset_data ===\")\n",
        "\n",
        "def clean_fat_id(df):\n",
        "    \"\"\"Fungsi untuk membersihkan kolom fat_id\"\"\"\n",
        "    if 'fat_id' in df.columns:\n",
        "        df['fat_id'] = (\n",
        "            df['fat_id']\n",
        "            .astype(str)\n",
        "            .str.strip()\n",
        "            .str.upper()  # Standardisasi ke uppercase\n",
        "            .str.replace(r'[\\s\\t\\-]+', '', regex=True)  # Hapus semua whitespace, tab, dan hyphen\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# Fungsi untuk memproses kolom fat_id yang memiliki format range\n",
        "def expand_fat_id_ranges(df):\n",
        "    # Buat list untuk menyimpan baris yang sudah di-expand\n",
        "    expanded_rows = []\n",
        "\n",
        "    # Iterasi melalui setiap baris di DataFrame\n",
        "    for _, row in df.iterrows():\n",
        "        fat_id = str(row['fat_id']).strip() if pd.notna(row['fat_id']) else ''\n",
        "\n",
        "        # Jika fat_id memiliki format range (mengandung '-')\n",
        "        if '-' in fat_id:\n",
        "            # Split menjadi dua bagian\n",
        "            id_parts = [part.strip() for part in fat_id.split('-') if part.strip()]\n",
        "\n",
        "            # Jika format range valid (ada dua bagian setelah split)\n",
        "            if len(id_parts) == 2:\n",
        "                # Buat dua baris baru dengan fat_id yang berbeda\n",
        "                row1 = row.copy()\n",
        "                row1['fat_id'] = id_parts[0]\n",
        "                expanded_rows.append(row1)\n",
        "\n",
        "                row2 = row.copy()\n",
        "                row2['fat_id'] = id_parts[1]\n",
        "                expanded_rows.append(row2)\n",
        "            else:\n",
        "                # Jika format tidak valid, simpan baris asli\n",
        "                expanded_rows.append(row)\n",
        "        else:\n",
        "            # Jika bukan format range, simpan baris asli\n",
        "            expanded_rows.append(row)\n",
        "\n",
        "    # Buat DataFrame baru dari baris yang sudah di-expand\n",
        "    return pd.DataFrame(expanded_rows)\n",
        "\n",
        "# Bersihkan dan expand fat_id di aset_data\n",
        "aset_data = clean_fat_id(aset_data)\n",
        "aset_data = expand_fat_id_ranges(aset_data)\n",
        "aset_data.drop_duplicates(subset='fat_id', keep=\"first\", inplace=True)\n",
        "print(\"‚úÖ Split user_terminals from aset_data (including expanding fat_id ranges).\")\n",
        "\n",
        "# 1. Split Data untuk Tabel user_terminals\n",
        "user_terminals = aset_data[[\n",
        "    \"hostname_olt\", \"latitude_olt\", \"longitude_olt\", \"brand_olt\", \"type_olt\",\n",
        "    \"kapasitas_olt\", \"kapasitas_port_olt\", \"olt_port\", \"olt\", \"interface_olt\",\n",
        "    \"fdt_id\", \"status_osp_amarta_fdt\", \"jumlah_splitter_fdt\", \"kapasitas_splitter_fdt\",\n",
        "    \"fdt_new_existing\", \"port_fdt\", \"latitude_fdt\", \"longitude_fdt\",\n",
        "    \"fat_id\", \"jumlah_splitter_fat\", \"kapasitas_splitter_fat\", \"latitude_fat\", \"longitude_fat\",\n",
        "    \"status_osp_amarta_fat\", \"fat_kondisi\", \"fat_filter_pemakaian\", \"keterangan_full\",\n",
        "    \"fat_id_x\", \"filter_fat_cap\"\n",
        "]].copy()\n",
        "user_terminals = clean_fat_id(user_terminals)\n",
        "print(\"‚úÖ Split user_terminals from aset_data.\")\n",
        "\n",
        "# 2-5. Split Data untuk tabel lainnya\n",
        "tables = {\n",
        "    \"cluster_data\": [\"latitude_cluster\", \"longitude_cluster\", \"area_kp\", \"kota_kab\", \"kecamatan\", \"kelurahan\", \"up3\", \"ulp\", \"fat_id\"],\n",
        "    \"home_connected_data\": [\"hc_old\", \"hc_icrm\", \"total_hc\", \"cleansing_hp\", \"fat_id\"],\n",
        "    \"dokumentasi_data\": [\"status_osp_amarta_fat\", \"link_dokumen_feeder\", \"keterangan_dokumen\", \"link_data_aset\", \"keterangan_data_aset\", \"link_maps\", \"update_aset\", \"amarta_update\", \"fat_id\"],\n",
        "    \"additional_info_data\": [\"pa\", \"tanggal_rfs\", \"mitra\", \"kategori\", \"sumber_datek\", \"fat_id\"]\n",
        "}\n",
        "\n",
        "for name, cols in tables.items():\n",
        "    globals()[name] = aset_data[cols].copy()\n",
        "    globals()[name] = clean_fat_id(globals()[name])\n",
        "    print(f\"‚úÖ Split {name} from aset_data.\")\n",
        "\n",
        "# ========================= Split dan Filter Data dari user_data =========================\n",
        "print(\"\\n=== Splitting dan Filtering Data from user_data ===\")\n",
        "\n",
        "pelanggan_data = user_data[[\n",
        "    \"id_permohonan\", \"sid\", \"cust_name\", \"telpn\",\n",
        "    \"latitude_pelanggan\", \"longitude_pelanggan\", \"fat_id\", \"notes\"\n",
        "]].copy()\n",
        "pelanggan_data = clean_fat_id(pelanggan_data)\n",
        "print(\"‚úÖ Split pelanggan_data from user_data.\")\n",
        "\n",
        "# Validasi fat_id\n",
        "if 'fat_id' in user_terminals.columns:\n",
        "    # Dapatkan semua fat_id valid dari user_terminals\n",
        "    valid_fat_ids = set(user_terminals['fat_id'].unique())\n",
        "    print(f\"‚ÑπÔ∏è Ditemukan {len(valid_fat_ids)} unique fat_ids di user_terminals.\")\n",
        "\n",
        "    # Filter pelanggan_data\n",
        "    valid_pelanggan_data = pelanggan_data[pelanggan_data['fat_id'].isin(valid_fat_ids)].copy()\n",
        "    invalid_pelanggan_data = pelanggan_data[~pelanggan_data['fat_id'].isin(valid_fat_ids)].copy()\n",
        "\n",
        "    print(f\"‚úÖ {len(valid_pelanggan_data)} baris valid, {len(invalid_pelanggan_data)} baris invalid.\")\n",
        "\n",
        "    if not invalid_pelanggan_data.empty:\n",
        "        print(\"‚ö†Ô∏è Contoh fat_id tidak valid:\", invalid_pelanggan_data['fat_id'].unique()[:10])\n",
        "else:\n",
        "    print(\"‚ùå Kolom 'fat_id' tidak ditemukan di user_terminals\")\n",
        "    valid_pelanggan_data = pd.DataFrame(columns=pelanggan_data.columns)\n",
        "    invalid_pelanggan_data = pelanggan_data.copy()\n",
        "\n",
        "# Cleaning tambahan untuk pelanggan\n",
        "valid_pelanggan_data['id_permohonan'] = valid_pelanggan_data['id_permohonan'].astype(str).str.strip()\n",
        "valid_pelanggan_data.drop_duplicates(subset='id_permohonan', keep=\"first\", inplace=True)\n",
        "\n",
        "# ========================= Final Validation =========================\n",
        "print(\"\\n=== Final Validation ===\")\n",
        "\n",
        "# Pastikan tidak ada fat_id yang tidak valid\n",
        "missing_fat_ids = set(valid_pelanggan_data['fat_id']) - set(user_terminals['fat_id'])\n",
        "if missing_fat_ids:\n",
        "    print(f\"‚ùå Masih ada {len(missing_fat_ids)} fat_id yang tidak valid!\")\n",
        "    print(\"Contoh:\", list(missing_fat_ids)[:5])\n",
        "else:\n",
        "    print(\"‚úÖ Semua fat_id di valid_pelanggan_data valid!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0Cb_2lj3lZV",
        "outputId": "be9df6fb-4002-4556-ff5a-da4dd88cc8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Splitting Data from aset_data ===\n",
            "‚úÖ Split user_terminals from aset_data (including expanding fat_id ranges).\n",
            "‚úÖ Split user_terminals from aset_data.\n",
            "‚úÖ Split cluster_data from aset_data.\n",
            "‚úÖ Split home_connected_data from aset_data.\n",
            "‚úÖ Split dokumentasi_data from aset_data.\n",
            "‚úÖ Split additional_info_data from aset_data.\n",
            "\n",
            "=== Splitting dan Filtering Data from user_data ===\n",
            "‚úÖ Split pelanggan_data from user_data.\n",
            "‚ÑπÔ∏è Ditemukan 39205 unique fat_ids di user_terminals.\n",
            "‚úÖ 131050 baris valid, 7966 baris invalid.\n",
            "‚ö†Ô∏è Contoh fat_id tidak valid: ['MLN' 'CATV' 'MLGA026' 'PBLA000' 'SITA001' 'TBNA089' 'MLGA297'\n",
            " 'SDAA100733' 'PBLA10092' 'MDNA1019']\n",
            "\n",
            "=== Final Validation ===\n",
            "‚úÖ Semua fat_id di valid_pelanggan_data valid!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan data ke file CSV\n",
        "user_terminals.to_csv(\"data_clean/fiber.csv\", index=False)\n",
        "print(\"‚úÖ Data OLT berhasil disimpan ke data_clean/OLT.csv\")\n",
        "pelanggan_data.to_csv(\"data_clean/Pelanggan.csv\", index=False)\n",
        "print(\"‚úÖ Data Pelanggan berhasil disimpan ke data_clean/Pelanggan.csv\")\n",
        "cluster_data.to_csv(\"data_clean/Clusters.csv\", index=False)\n",
        "print(\"‚úÖ Data Clusters berhasil disimpan ke data_clean/Clusters.csv\")\n",
        "home_connected_data.to_csv(\"data_clean/HomeConnected.csv\", index=False)\n",
        "print(\"‚úÖ Data Home Connected berhasil disimpan ke data_clean/HomeConnected.csv\")\n",
        "dokumentasi_data.to_csv(\"data_clean/Dokumentasi.csv\", index=False)\n",
        "print(\"‚úÖ Data Dokumentasi berhasil disimpan ke data_clean/Dokumentasi.csv\")\n",
        "additional_info_data.to_csv(\"data_clean/AdditionalInformation.csv\", index=False)\n",
        "print(\"‚úÖ Data Additional Information berhasil disimpan ke data_clean/AdditionalInformation.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOeln8uI4B5i",
        "outputId": "b31313e7-c421-4067-fd84-62fc9a19a25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data OLT berhasil disimpan ke data_clean/OLT.csv\n",
            "‚úÖ Data Pelanggan berhasil disimpan ke data_clean/Pelanggan.csv\n",
            "‚úÖ Data Clusters berhasil disimpan ke data_clean/Clusters.csv\n",
            "‚úÖ Data Home Connected berhasil disimpan ke data_clean/HomeConnected.csv\n",
            "‚úÖ Data Dokumentasi berhasil disimpan ke data_clean/Dokumentasi.csv\n",
            "‚úÖ Data Additional Information berhasil disimpan ke data_clean/AdditionalInformation.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aset_data.to_csv(\"aset_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "agSm_8bR1sd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Buat ZIP dari folder 'data_clean'\n",
        "shutil.make_archive(\"data_clean\", 'zip', \"data_clean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TfaDSdgDvgUK",
        "outputId": "506b541f-6318-4120-bd9d-449f420bb0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data_clean.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path folder yang ingin dibersihkan\n",
        "folder_path = \"data_clean\"\n",
        "\n",
        "# Ambil semua file di dalam folder\n",
        "files = glob.glob(os.path.join(folder_path, \"*\"))\n",
        "\n",
        "# Hapus satu per satu\n",
        "for file in files:\n",
        "    os.remove(file)\n",
        "\n",
        "print(\"‚úÖ Semua file di dalam folder 'data_clean' berhasil dihapus.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBfZwc571Rvb",
        "outputId": "ea599897-71ec-4b7f-9b5f-aa9c785db915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Semua file di dalam folder 'data_clean' berhasil dihapus.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy psycopg2-binary"
      ],
      "metadata": {
        "id": "Le79EkPT01GA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d06a502-47d9-465a-ef10-680361de8668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.40)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.13.2)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Library untuk koneksi database\n",
        "import sqlalchemy\n",
        "import psycopg2\n",
        "\n",
        "# Diasumsikan DataFrame (user_terminals, cluster_data, etc.) sudah dibuat/diproses sebelumnya.\n",
        "# Diasumsikan fungsi pembersihan data sudah didefinisikan di awal script.\n",
        "\n",
        "# ========================= Database Connection Setup =========================\n",
        "print(\"\\n=== DATABASE CONNECTION SETUP ===\")\n",
        "\n",
        "# Mendapatkan kredensial database dari Environment Variables atau Colab Secrets\n",
        "# Sesuaikan bagian ini dengan cara Anda menyimpan secrets\n",
        "try:\n",
        "    # Jika Anda menggunakan google.colab.userdata secara langsung:\n",
        "    DB_HOST = userdata.get(\"SUPABASE_DB_HOST\")\n",
        "    DB_DATABASE = userdata.get(\"SUPABASE_DB_NAME\")\n",
        "    DB_USER = userdata.get(\"SUPABASE_DB_USER\")\n",
        "    DB_PASSWORD = userdata.get(\"SUPABASE_DB_PASSWORD\")\n",
        "    DB_PORT = userdata.get(\"SUPABASE_DB_PORT\")\n",
        "\n",
        "    if not all([DB_HOST, DB_DATABASE, DB_USER, DB_PASSWORD]):\n",
        "        raise ValueError(\"Database credentials incomplete. Check SUPABASE_DB_HOST, SUPABASE_DB_NAME, SUPABASE_DB_USER, SUPABASE_DB_PASSWORD.\")\n",
        "\n",
        "    print(\"‚úÖ Database credentials loaded successfully.\")\n",
        "\n",
        "except (KeyError, ValueError) as e:\n",
        "    print(f\"‚ùå Failed to load database credentials: {e}\")\n",
        "    print(\"‚ÑπÔ∏è Please ensure Colab Secrets or Environment Variables are set correctly.\")\n",
        "    # Anda mungkin ingin menghentikan eksekusi jika kredensial tidak ada\n",
        "    # exit()\n",
        "    engine = None # Set engine menjadi None agar impor dilewati\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An unexpected error occurred while loading credentials: {e}\")\n",
        "    engine = None # Set engine menjadi None agar impor dilewati"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WAi18-L0tAj",
        "outputId": "30229372-8ced-49d7-9a26-338439e9a9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DATABASE CONNECTION SETUP ===\n",
            "‚úÖ Database credentials loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "create_schema_sql = text(\"\"\"\n",
        "-- Tabel utama: user_terminals\n",
        "CREATE TABLE IF NOT EXISTS user_terminals (\n",
        "    fat_id VARCHAR(255) PRIMARY KEY,\n",
        "    hostname_olt VARCHAR(255),\n",
        "    latitude_olt FLOAT,\n",
        "    longitude_olt FLOAT,\n",
        "    brand_olt VARCHAR(255),\n",
        "    type_olt VARCHAR(255),\n",
        "    kapasitas_olt INTEGER,\n",
        "    kapasitas_port_olt INTEGER,\n",
        "    olt_port INTEGER,\n",
        "    olt VARCHAR(255),\n",
        "    interface_olt VARCHAR(255),\n",
        "    fdt_id VARCHAR(255),\n",
        "    status_osp_amarta_fdt VARCHAR(255),\n",
        "    jumlah_splitter_fdt INTEGER,\n",
        "    kapasitas_splitter_fdt INTEGER,\n",
        "    fdt_new_existing VARCHAR(255),\n",
        "    port_fdt INTEGER,\n",
        "    latitude_fdt FLOAT,\n",
        "    longitude_fdt FLOAT,\n",
        "    jumlah_splitter_fat INTEGER,\n",
        "    kapasitas_splitter_fat INTEGER,\n",
        "    latitude_fat FLOAT,\n",
        "    longitude_fat FLOAT,\n",
        "    status_osp_amarta_fat VARCHAR(255),\n",
        "    fat_kondisi VARCHAR(255),\n",
        "    fat_filter_pemakaian VARCHAR(255),\n",
        "    keterangan_full VARCHAR(255),\n",
        "    fat_id_x VARCHAR(255),\n",
        "    filter_fat_cap VARCHAR(255)\n",
        ");\n",
        "\n",
        "-- Tabel clusters\n",
        "CREATE TABLE IF NOT EXISTS clusters (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    latitude_cluster FLOAT,\n",
        "    longitude_cluster FLOAT,\n",
        "    area_kp VARCHAR(255),\n",
        "    kota_kab VARCHAR(255),\n",
        "    kecamatan VARCHAR(255),\n",
        "    kelurahan VARCHAR(255),\n",
        "    up3 VARCHAR(255),\n",
        "    ulp VARCHAR(255),\n",
        "    fat_id VARCHAR(255) NOT NULL REFERENCES user_terminals(fat_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "-- Tabel home_connecteds\n",
        "CREATE TABLE IF NOT EXISTS home_connecteds (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    hc_old INTEGER,\n",
        "    hc_icrm INTEGER,\n",
        "    total_hc INTEGER,\n",
        "    cleansing_hp VARCHAR(255),\n",
        "    fat_id VARCHAR(255) NOT NULL REFERENCES user_terminals(fat_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "-- Tabel dokumentasis\n",
        "CREATE TABLE IF NOT EXISTS dokumentasis (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    status_osp_amarta_fat VARCHAR(255),\n",
        "    link_dokumen_feeder TEXT,\n",
        "    keterangan_dokumen TEXT,\n",
        "    link_data_aset TEXT,\n",
        "    keterangan_data_aset TEXT,\n",
        "    link_maps TEXT,\n",
        "    update_aset VARCHAR(255),\n",
        "    amarta_update VARCHAR(255),\n",
        "    fat_id VARCHAR(255) NOT NULL REFERENCES user_terminals(fat_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "-- Tabel additional_informations\n",
        "CREATE TABLE IF NOT EXISTS additional_informations (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    pa VARCHAR(255),\n",
        "    tanggal_rfs DATE,\n",
        "    mitra VARCHAR(255),\n",
        "    kategori VARCHAR(255),\n",
        "    sumber_datek VARCHAR(255),\n",
        "    fat_id VARCHAR(255) NOT NULL REFERENCES user_terminals(fat_id) ON DELETE CASCADE\n",
        ");\n",
        "\n",
        "-- Tabel pelanggan\n",
        "CREATE TABLE IF NOT EXISTS pelanggans (\n",
        "    id_permohonan VARCHAR(255) PRIMARY KEY,\n",
        "    sid VARCHAR(255),\n",
        "    cust_name VARCHAR(255),\n",
        "    telpn VARCHAR(255),\n",
        "    latitude_pelanggan FLOAT,\n",
        "    longitude_pelanggan FLOAT,\n",
        "    fat_id VARCHAR(255) NOT NULL REFERENCES user_terminals(fat_id) ON DELETE CASCADE,\n",
        "    notes TEXT\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "# Eksekusi query untuk membuat tabel\n",
        "if engine:\n",
        "    with engine.connect() as conn:\n",
        "        conn.execute(create_schema_sql)\n",
        "        conn.commit()\n",
        "        print(\"‚úÖ Semua tabel berhasil dibuat di Supabase database.\")\n",
        "else:\n",
        "    print(\"‚ùå Koneksi database gagal, tidak bisa membuat tabel.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w07lr5EYqxXD",
        "outputId": "6735ea34-4b86-461c-998d-6033e7ad7a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Semua tabel berhasil dibuat di Supabase database.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Koneksi ke database Supabase\n",
        "DATABASE_URL = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_DATABASE}\"\n",
        "engine = create_engine(DATABASE_URL)\n",
        "\n",
        "# Perintah SQL untuk menghapus semua tabel\n",
        "drop_tables_sql = text(\"\"\"\n",
        "DROP TABLE IF EXISTS pelanggans CASCADE;\n",
        "DROP TABLE IF EXISTS additional_informations CASCADE;\n",
        "DROP TABLE IF EXISTS dokumentasis CASCADE;\n",
        "DROP TABLE IF EXISTS home_connecteds CASCADE;\n",
        "DROP TABLE IF EXISTS clusters CASCADE;\n",
        "DROP TABLE IF EXISTS user_terminals CASCADE;\n",
        "\"\"\")\n",
        "\n",
        "# Eksekusi perintah\n",
        "if engine:\n",
        "    with engine.connect() as conn:\n",
        "        conn.execute(drop_tables_sql)\n",
        "        conn.commit()\n",
        "        print(\"‚úÖ Semua tabel telah dihapus dari database Supabase.\")\n",
        "else:\n",
        "    print(\"‚ùå Koneksi database gagal, tidak bisa menghapus tabel.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH5WMbPUDzNR",
        "outputId": "3b586e40-5923-41e1-cb3a-eec28ed5bdfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Semua tabel telah dihapus dari database Supabase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_tables_sql = text(\"SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname='public';\")\n",
        "\n",
        "if engine:\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(check_tables_sql)\n",
        "        tables = [row[0] for row in result]\n",
        "        print(\"üìÇ Daftar tabel yang berhasil dibuat:\")\n",
        "        for table in tables:\n",
        "            print(f\"- {table}\")\n",
        "else:\n",
        "    print(\"‚ùå Tidak bisa memverifikasi karena koneksi database gagal.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDtOT7oP8mpb",
        "outputId": "0a6b2a81-69b1-4ba6-89b5-0202f2882d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Daftar tabel yang berhasil dibuat:\n",
            "- user_terminals\n",
            "- clusters\n",
            "- home_connecteds\n",
            "- dokumentasis\n",
            "- additional_informations\n",
            "- pelanggans\n",
            "- datekasetall\n",
            "- spatial_ref_sys\n",
            "- data_aset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat Database URL untuk SQLAlchemy\n",
        "engine = None # Inisialisasi engine\n",
        "if DB_HOST and DB_DATABASE and DB_USER and DB_PASSWORD: # Hanya coba buat URL jika kredensial dasar ada\n",
        "    # Gunakan 'postgresql' sebagai dialek\n",
        "    db_url = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_DATABASE}\"\n",
        "    print(f\"‚ÑπÔ∏è Attempting to connect to: postgresql://{DB_USER}:******@{DB_HOST}:{DB_PORT}/{DB_DATABASE}\")\n",
        "       # Membuat SQLAlchemy engine\n",
        "    try:\n",
        "        # pool_recycle handles connection timeouts (common in cloud databases)\n",
        "        engine = sqlalchemy.create_engine(db_url, pool_recycle=3600)\n",
        "        print(\"‚úÖ SQLAlchemy engine created successfully.\")\n",
        "        # Opsional: Cek koneksi\n",
        "        # with engine.connect() as connection:\n",
        "        #    print(\"‚úÖ Database connection test successful.\")\n",
        "        #    print(\"‚ÑπÔ∏è Database connection test successful.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to create SQLAlchemy engine or connect: {e}\")\n",
        "        print(\"‚ÑπÔ∏è Please check your credentials, host, port, database name, and ensure the database is accessible.\")\n",
        "        engine = None # Pastikan engine None jika gagal\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Insufficient database credentials to attempt connection.\")\n",
        "\n",
        "\n",
        "# ========================= Data Import Order =========================\n",
        "# Definisikan urutan impor berdasarkan relasi Foreign Key.\n",
        "# Tabel yang menjadi referensi (user_terminals) HARUS diimpor duluan.\n",
        "# Tabel lain yang mereferensi user_terminals dapat diimpor setelahnya.\n",
        "# PASTIKAN NAMA VARIABEL DATAFRAME (user_terminals, cluster_data, dll.) DI SINI\n",
        "# SAMA DENGAN NAMA VARIABEL YANG DIHASILKAN OLEH CELL-CELL SEBELUMNYA.\n",
        "import_order = [\n",
        "    {\"df\": user_terminals, \"table_name\": \"user_terminals\"},\n",
        "    {\"df\": cluster_data, \"table_name\": \"clusters\"},\n",
        "    {\"df\": home_connected_data, \"table_name\": \"home_connecteds\"},\n",
        "    {\"df\": dokumentasi_data, \"table_name\": \"dokumentasis\"},\n",
        "    {\"df\": additional_info_data, \"table_name\": \"additional_informations\"},\n",
        "    # Gunakan DataFrame pelanggan yang sudah difilter (valid_pelanggan_data)\n",
        "    # karena tabel pelanggans mereferensi user_terminals(fat_id) dengan NOT NULL\n",
        "    {\"df\": valid_pelanggan_data, \"table_name\": \"pelanggans\"},\n",
        "    # Anda bisa menambahkan tabel invalid_pelanggans jika ada dan ingin menyimpannya juga\n",
        "    # {\"df\": invalid_pelanggan_data, \"table_name\": \"invalid_pelanggans\"},\n",
        "]\n",
        "\n",
        "# ========================= Import DataFrames to Supabase =========================\n",
        "print(\"\\n=== IMPORTING DATA TO SUPABASE ===\")\n",
        "\n",
        "# Definisikan perilaku jika tabel sudah ada:\n",
        "# 'fail': Akan error jika tabel sudah ada.\n",
        "# 'replace': Tabel akan dihapus lalu dibuat ulang sebelum data diimpor.\n",
        "# 'append': Data akan ditambahkan ke tabel yang sudah ada.\n",
        "# Pilih 'append' jika Anda ingin menambahkan data baru tanpa menghapus data lama.\n",
        "# Pilih 'replace' jika Anda ingin me-reload total data di tabel (hati-hati!).\n",
        "if_exists_behavior = 'append' # <<-- SESUAIKAN INI ('append' atau 'replace')\n",
        "\n",
        "if engine is not None: # Lanjutkan hanya jika engine berhasil dibuat\n",
        "    for item in import_order:\n",
        "        df_to_import = item.get(\"df\") # Gunakan .get() untuk safety jika variabel DF tidak ada\n",
        "        table_name = item.get(\"table_name\")\n",
        "\n",
        "        # Periksa apakah DataFrame valid sebelum diimpor\n",
        "        if df_to_import is None:\n",
        "            print(f\"\\n‚ö†Ô∏è DataFrame variable for table '{table_name}' is not defined. Skipping import.\")\n",
        "            continue\n",
        "        if not isinstance(df_to_import, pd.DataFrame) or df_to_import.empty:\n",
        "            print(f\"\\n‚ö†Ô∏è DataFrame for '{table_name}' is empty or invalid ({type(df_to_import)}). Skipping import.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        print(f\"\\n‚ÑπÔ∏è Importing {len(df_to_import)} rows to table '{table_name}'...\")\n",
        "\n",
        "        try:\n",
        "            # Menggunakan metode to_sql pandas\n",
        "            # name: Nama tabel di database.\n",
        "            # con: SQLAlchemy engine atau koneksi database.\n",
        "            # if_exists: Perilaku jika tabel sudah ada ('append' atau 'replace').\n",
        "            # index=False: Tidak memasukkan index DataFrame sebagai kolom di tabel.\n",
        "            # dtype: Opsional, mapping eksplisit tipe data Pandas ke tipe data SQL.\n",
        "            #        Sangat direkomendasikan untuk mengontrol mapping tipe data,\n",
        "            #        terutama untuk INTEGER yang bisa nullable (Int64 -> BigInteger)\n",
        "            #        atau Date/Timestamp.\n",
        "            #        Lihat skema Supabase Anda untuk mencocokkan tipe data.\n",
        "\n",
        "            # Contoh penggunaan dtype eksplisit berdasarkan skema Supabase Anda:\n",
        "            # (Tambahkan atau sesuaikan kolom dan tipe data di sini)\n",
        "            dtype_mapping = {\n",
        "                 \"fat_id\": sqlalchemy.types.VARCHAR(255), # Primary/Foreign Key\n",
        "                 \"hostname_olt\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"latitude_olt\": sqlalchemy.types.FLOAT,\n",
        "                 \"longitude_olt\": sqlalchemy.types.FLOAT,\n",
        "                 \"brand_olt\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"type_olt\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"kapasitas_olt\": sqlalchemy.types.BigInteger, # pd.Int64 -> SQL BIGINT\n",
        "                 \"kapasitas_port_olt\": sqlalchemy.types.BigInteger,\n",
        "                 \"olt_port\": sqlalchemy.types.BigInteger,\n",
        "                 \"olt\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"interface_olt\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"fdt_id\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"status_osp_amarta_fdt\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"jumlah_splitter_fdt\": sqlalchemy.types.BigInteger,\n",
        "                 \"kapasitas_splitter_fdt\": sqlalchemy.types.BigInteger,\n",
        "                 \"fdt_new_existing\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"port_fdt\": sqlalchemy.types.BigInteger,\n",
        "                 \"latitude_fdt\": sqlalchemy.types.FLOAT,\n",
        "                 \"longitude_fdt\": sqlalchemy.types.FLOAT,\n",
        "                 \"jumlah_splitter_fat\": sqlalchemy.types.BigInteger,\n",
        "                 \"kapasitas_splitter_fat\": sqlalchemy.types.BigInteger,\n",
        "                 \"latitude_fat\": sqlalchemy.types.FLOAT, # Jika ada di user_terminals split\n",
        "                 \"longitude_fat\": sqlalchemy.types.FLOAT, # Jika ada di user_terminals split\n",
        "                 \"status_osp_amarta_fat\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"fat_kondisi\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"fat_filter_pemakaian\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"keterangan_full\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"fat_id_x\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"filter_fat_cap\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"latitude_cluster\": sqlalchemy.types.FLOAT,\n",
        "                 \"longitude_cluster\": sqlalchemy.types.FLOAT,\n",
        "                 \"area_kp\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"kota_kab\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"kecamatan\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"kelurahan\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"up3\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"ulp\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"hc_old\": sqlalchemy.types.BigInteger,\n",
        "                 \"hc_icrm\": sqlalchemy.types.BigInteger,\n",
        "                 \"total_hc\": sqlalchemy.types.BigInteger,\n",
        "                 \"cleansing_hp\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"pa\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"tanggal_rfs\": sqlalchemy.types.Date, # Pastikan ini cocok dengan tipe data di DB dan DF (datetime/date)\n",
        "                 \"mitra\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"kategori\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"sumber_datek\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"id_permohonan\": sqlalchemy.types.VARCHAR(255), # Primary Key pelanggans\n",
        "                 \"sid\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"cust_name\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"telpn\": sqlalchemy.types.VARCHAR(255),\n",
        "                 \"latitude_pelanggan\": sqlalchemy.types.FLOAT,\n",
        "                 \"longitude_pelanggan\": sqlalchemy.types.FLOAT,\n",
        "                 \"notes\": sqlalchemy.types.Text, # Gunakan TEXT untuk VARCHAR panjang atau tanpa batas\n",
        "            }\n",
        "\n",
        "            # Filter dtype_mapping hanya untuk kolom yang ada di DataFrame saat ini\n",
        "            valid_dtype_mapping = {col: dtype for col, dtype in dtype_mapping.items() if col in df_to_import.columns}\n",
        "\n",
        "\n",
        "            df_to_import.to_sql(\n",
        "                name=table_name,\n",
        "                con=engine,\n",
        "                if_exists=if_exists_behavior,\n",
        "                index=False,\n",
        "                dtype=valid_dtype_mapping # Gunakan dictionary dtype yang sudah divalidasi\n",
        "            )\n",
        "            print(f\"‚úÖ Successfully imported {len(df_to_import)} rows to '{table_name}'.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to import data to '{table_name}': {e}\")\n",
        "            print(\"‚ÑπÔ∏è Check for potential issues:\")\n",
        "            print(\" ¬† - Table schema matching DataFrame columns (names, order, case-sensitivity).\")\n",
        "            print(\" ¬† - Data types compatibility (e.g., unexpected values in INTEGER columns, invalid dates).\")\n",
        "            print(\" ¬† - Foreign key violations (ensure fat_id in dependent tables exists in user_terminals.fat_id).\")\n",
        "            print(\" ¬† - Primary key violations (ensure no duplicate primary key values).\")\n",
        "            print(\" ¬† - Database connection stability.\")\n",
        "            # Dalam notebook, Anda mungkin ingin melihat error lengkap\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            # Decide if you want to stop the notebook execution here or continue\n",
        "            # raise # Uncomment to stop execution on import error\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Data import skipped because database connection could not be established.\")\n",
        "\n",
        "\n",
        "# ========================= Close Connection (Good Practice) =========================\n",
        "# SQLAlchemy engine mengelola koneksi dalam pool. dispose() akan menutup semua koneksi di pool.\n",
        "# Ini adalah praktik yang baik di akhir script atau notebook cell.\n",
        "if 'engine' in locals() and engine:\n",
        "    try:\n",
        "        engine.dispose()\n",
        "        print(\"\\n‚ÑπÔ∏è Database engine disposed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error disposing database engine: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "Lap_bHEoGT2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b02321-9e46-4f72-b7c1-7c7fa1b474c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Attempting to connect to: postgresql://postgres.gbzmeqwfjliifwqpyzvl:******@aws-0-us-west-1.pooler.supabase.com:6543/postgres\n",
            "‚úÖ SQLAlchemy engine created successfully.\n",
            "\n",
            "=== IMPORTING DATA TO SUPABASE ===\n",
            "\n",
            "‚ÑπÔ∏è Importing 39205 rows to table 'user_terminals'...\n",
            "‚úÖ Successfully imported 39205 rows to 'user_terminals'.\n",
            "\n",
            "‚ÑπÔ∏è Importing 39205 rows to table 'clusters'...\n",
            "‚úÖ Successfully imported 39205 rows to 'clusters'.\n",
            "\n",
            "‚ÑπÔ∏è Importing 39205 rows to table 'home_connecteds'...\n",
            "‚úÖ Successfully imported 39205 rows to 'home_connecteds'.\n",
            "\n",
            "‚ÑπÔ∏è Importing 39205 rows to table 'dokumentasis'...\n",
            "‚úÖ Successfully imported 39205 rows to 'dokumentasis'.\n",
            "\n",
            "‚ÑπÔ∏è Importing 39205 rows to table 'additional_informations'...\n",
            "‚úÖ Successfully imported 39205 rows to 'additional_informations'.\n",
            "\n",
            "‚ÑπÔ∏è Importing 131034 rows to table 'pelanggans'...\n",
            "‚úÖ Successfully imported 131034 rows to 'pelanggans'.\n",
            "\n",
            "‚ÑπÔ∏è Database engine disposed.\n"
          ]
        }
      ]
    }
  ]
}